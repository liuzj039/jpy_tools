"""
DE analysis tools
"""
from logging import log
import pandas as pd
import numpy as np
import scanpy as sc
import matplotlib.pyplot as plt
import patchworklib as pw
import matplotlib as mpl
import seaborn as sns
import anndata
from scipy.stats import spearmanr, pearsonr, zscore
from loguru import logger
from io import StringIO
from concurrent.futures import ProcessPoolExecutor as Mtp
from concurrent.futures import ThreadPoolExecutor as MtT
from joblib import Parallel, delayed
import sh
import h5py
from tqdm import tqdm
import scvi
from typing import (
    Dict,
    List,
    Optional,
    Union,
    Sequence,
    Literal,
    Any,
    Tuple,
    Iterator,
    Mapping,
    Callable,
)
import collections
from xarray import corr
from . import basic, diffxpy
from ..rTools import rcontext
from ..otherTools import F, pwStack, pwShow, MuteInfo

def getGeneEnrichmentScore(ad:sc.AnnData, genes:Union[str, list], cluster:str, layer:str = 'normalize_log', permuteTime:int=1000, seed:int=39) -> pd.DataFrame:
    '''This function calculates the enrichment score of a given set of genes in a specific cluster of cells using a permutation-based approach.
    Reimplementation of Enrichment score defined in 10.1038/s41477-021-00922-0

    Parameters
    ----------
    ad : sc.AnnData
        `ad` is an AnnData object, which is a data structure commonly used in single-cell genomics to store and manipulate gene expression data along with associated metadata.
    genes : Union[str, list]
        The genes of interest that will be used to calculate the enrichment score. It can be either a single gene or a list of genes.
    cluster : str
        The `cluster` parameter is a string that specifies the name of the column in the `ad.obs` dataframe that contains the cluster labels for each cell. The function groups the cells by their cluster labels and calculates the mean expression of the specified genes for each cluster. It then compares this to the mean
    layer : str, optional
        The layer parameter specifies which layer of gene expression data to use for the analysis. It has a default value of 'normalize_log', which suggests that the data has been normalized and log-transformed.
    permuteTime : int, optional
        permuteTime is an integer parameter that specifies the number of times to permute the cluster labels and calculate the enrichment score. The higher the value of permuteTime, the more accurate the enrichment score will be, but it will also take longer to compute.
    seed : int, optional
        The seed parameter is an integer used to initialize the random number generator. It ensures that the random permutations generated during the permutation test are reproducible.

    Returns
    -------
        a pandas DataFrame containing the enrichment score (z-score) for the specified genes in the specified cluster, calculated using the method described in the paper with the DOI 10.1038/s41477-021-00922-0. The enrichment score is calculated by comparing the mean expression of the genes in the true cluster to the mean expression of the genes in permuted clusters, and

    '''
    ad = ad[:, genes]
    df_mtx = ad.to_df(layer).join(ad.obs[cluster])
    df_true = df_mtx.groupby(cluster).agg('mean')
    ls_permuteAr = []
    for i in tqdm(range(permuteTime)):
        df_mtx[cluster] = df_mtx[cluster].sample(frac=1, random_state=seed).values
        df_permuted = df_mtx.groupby(cluster).agg('mean')
        ls_permuteAr.append(df_permuted.values)
    ar_permute = np.stack(ls_permuteAr)
    ar_meanPermute = ar_permute.mean(0)
    ar_stdPermute = ar_permute.std(0)
    zscore = (df_true - ar_meanPermute) / ar_stdPermute
    return zscore


def getBgGene(
    ad,
    ls_gene,
    layer="normalize_log",
    bins=50,
    seed=0,
    usePreBin: str = None,
    multi=1,
    replacement=True,
):
    "replacement: if True, ls_gene will be included in the result"
    if not usePreBin:
        ad.var["means_ForPickMock"] = ad.to_df(layer).mean()
        ad.var["bins_ForPickMock"] = pd.qcut(
            ad.var["means_ForPickMock"], bins, duplicates="drop"
        )
    else:
        ad.var["bins_ForPickMock"] = ad.var[usePreBin]
    dt_binGeneCounts = ad.var.loc[ls_gene]["bins_ForPickMock"].value_counts().to_dict()
    if replacement:
        ls_gene = []
    ls_randomGene = (
        ad.var.query("index not in @ls_gene")
        .groupby("bins_ForPickMock", group_keys=False)
        .apply(
            lambda df: df.sample(
                n=dt_binGeneCounts[df["bins_ForPickMock"].iloc[0]] * multi,
                random_state=seed,
            )
        )
        .index.to_list()
    )
    return ls_randomGene


def getGeneModuleEnrichScore(
    ad,
    layer,
    ls_gene,
    times=100,
    groupby=None,
    targetOnly=True,
    disableBar=False,
    multi=False,
    **dt_paramsGetBgGene,
):
    """
    get gene module enrich score

    Parameters
    ----------
    ad : sc.AnnData
    layer :
        normalize_log
    ls_gene :
        gene list:
            ['a', 'b']
    times : int, optional
        by default 100
    groupby : _type_, optional
        by default None
    targetOnly : bool, optional
        remove shuffled gene results or not
    """

    ls_adGene = ad.var.index.to_list()
    st_notInGene = set(ls_gene) - set(ls_adGene)
    if len(st_notInGene):
        logger.warning(f"{ls_gene} not found in adata")
    ls_gene = [x for x in ls_gene if x in ls_adGene]
    if not multi:
        getBgGene(ad, ls_gene, layer=layer, **dt_paramsGetBgGene)
    ad.layers[f"{layer}_scaled"] = ad.layers[layer].copy()
    sc.pp.scale(ad, layer=f"{layer}_scaled")
    ls_bgGene = [
        getBgGene(
            ad,
            ls_gene,
            layer=layer,
            usePreBin="bins_ForPickMock",
            seed=x,
            **dt_paramsGetBgGene,
        )
        for x in tqdm(range(times), "get shuffled genes", disable=disableBar)
    ]
    if not groupby:
        ad.obs["temp_forES"] = "all"
        groupby = "temp_forES"
    dt_scaledMeanExp = {}
    for name, _ad in basic.splitAdata(ad, groupby, needName=True, copy=False):
        df_scaledExp = _ad.to_df(f"{layer}_scaled")
        dt_groupMeanExp = {"target": df_scaledExp[ls_gene].mean().mean()}
        for i, ls_bgGeneSingle in enumerate(ls_bgGene):
            dt_groupMeanExp[f"shuffle_{i}"] = (
                df_scaledExp[ls_bgGeneSingle].mean().mean()
            )
        dt_scaledMeanExp[name] = dt_groupMeanExp
    df_scaledMeanExp = pd.DataFrame(dt_scaledMeanExp).apply(zscore)
    if targetOnly:
        return df_scaledMeanExp.loc["target"].to_dict()
    else:
        return df_scaledMeanExp


def getGeneModuleEnrichScore_multiList(
    ad, layer, dt_gene, times=100, groupby=None, bins=50, **dt_paramsGetBgGene
):
    """
    get gene module enrich score

    Parameters
    ----------
    ad : sc.AnnData
    layer :
        normalize_log
    ls_gene :
        gene list:
            ['a', 'b']
    times : int, optional
        by default 100
    groupby : _type_, optional
        by default None
    targetOnly : bool, optional
        remove shuffled gene results or not
    """
    ad.var["means_ForPickMock"] = ad.to_df(layer).mean()
    ad.var["bins_ForPickMock"] = pd.qcut(
        ad.var["means_ForPickMock"], bins, duplicates="drop"
    )

    dt_result = {}
    for name, ls_gene in tqdm(
        dt_gene.items(), "get gene module enrich score", len(dt_gene)
    ):
        dt_result[name] = getGeneModuleEnrichScore(
            ad,
            layer,
            ls_gene,
            times,
            groupby,
            disableBar=True,
            multi=True,
            **dt_paramsGetBgGene,
        )
    return pd.DataFrame(dt_result)


def getUcellScore(
    ad: sc.AnnData,
    dt_deGene: Mapping[str, List[str]],
    layer: Optional[str],
    label,
    cutoff=0.2,
    batch=None,
):
    """
    use ucell calculate average expression info

    Parameters
    ----------
    ad : sc.AnnData
    dt_deGene : Mapping[str, List[str]]
        key is label, value is marker genes
    layer : Optional[str]
        must NOT be scaled data
    label :
        label for result.
    cutoff : float, optional
        by default 0.2
    """
    import rpy2.robjects as ro
    from rpy2.robjects.packages import importr
    from ..rTools import py2r, r2py

    R = ro.r
    ucell = importr("UCell")
    rBase = importr("base")

    layer = None if layer == "X" else layer
    for x in dt_deGene.keys():
        assert isinstance(x, str), f"`dt_deGene`: {x} is not a string"
    dtR_deGene = {x: R.c(*y) for x, y in dt_deGene.items()}
    dtR_deGene = R.list(**dtR_deGene)
    if batch:
        dfLs_ucellResults = []
        for _, _ad in basic.splitAdata(ad, batch, needName=True, copy=False):
            ss_forUcell = _ad.layers[layer] if layer else _ad.X
            ssR_forUcell = py2r(ss_forUcell.T)
            ssR_forUcell = R("`dimnames<-`")(
                ssR_forUcell,
                R.list(R.c(*_ad.var.index), R.c(*_ad.obs.index)),
            )

            r_scores = ucell.ScoreSignatures_UCell(ssR_forUcell, features=dtR_deGene)
            dfLs_ucellResults.append(r2py(rBase.as_data_frame(r_scores)))
        ad.obsm[f"ucell_score_{label}"] = pd.concat(dfLs_ucellResults).reindex(
            ad.obs.index
        )

    else:
        ss_forUcell = ad.layers[layer] if layer else ad.X
        ssR_forUcell = py2r(ss_forUcell.T)
        ssR_forUcell = R("`dimnames<-`")(
            ssR_forUcell,
            R.list(R.c(*ad.var.index), R.c(*ad.obs.index)),
        )

        r_scores = ucell.ScoreSignatures_UCell(ssR_forUcell, features=dtR_deGene)
        ad.obsm[f"ucell_score_{label}"] = r2py(rBase.as_data_frame(r_scores))

    if len(dt_deGene) > 1:
        ad.obs[f"ucell_celltype_{label}"] = ad.obsm[f"ucell_score_{label}"].pipe(
            lambda df: np.where(df.max(1) > cutoff, df.idxmax(1), "Unknown")
        )


def getGeneScore(
    ad: sc.AnnData,
    dt_Gene: Dict[str, List[str]],
    layer: Optional[str],
    label: str,
    func: Callable,
):
    """
    use gene score calculate average expression info

    Parameters
    ----------
    ad : sc.AnnData
    layer : Optional[str]
    dt_Gene : Dict[str, List[str]]
        key is label, value is marker genes
    label :
        label for result.
    func : Callable
        calculate function
    """
    df_results = pd.DataFrame(index=ad.obs.index, columns=dt_Gene.keys())
    for name, ls_gene in dt_Gene.items():
        _sr = ad[:, ls_gene].to_df(layer).apply(func, axis=1)
        df_results[name] = _sr
    ad.obsm[label] = df_results


def getOverlapInfo(
    adata: anndata.AnnData,
    key: str,
    markerDt: Mapping[str, List[str]],
    nTopGenes: int = 100,
) -> Mapping[str, List[str]]:
    """
    get overlap between marker genes with detected cluster-enriched genes

    Parameters
    ----------
    adata : anndata.AnnData
        after rank_genes_groups
    key : str
        key of rank_genes_groups
    markerDt : Mapping[str, List[str]]
        key is cell type, and value is corresponding marker genes
    nTopGenes : int, optional
        Number of cluster-enriched genes used, by default 100

    Returns
    -------
    Mapping[str, List[str]]
        key is cell type, and value is corresponding overlap genes
    """
    clusterEnrichedSt = set(
        sc.get.rank_genes_groups_df(adata, None, key=key)
        .groupby("group")
        .apply(lambda x: x.iloc[:nTopGenes]["names"])
    )
    overlapDt = {x: list(set(y) & clusterEnrichedSt) for x, y in markerDt.items()}
    return overlapDt


def detectMarkerGene(
    adata: anndata.AnnData,
    groupby: str,
    key_added: str,
    groups: Union[Literal["all"], Sequence[str], Callable[[str], bool]] = "all",
    use_raw: bool = False,
    layer: Optional[str] = None,
    method: Literal[
        "logreg", "t-test", "wilcoxon", "t-test_overestim_var"
    ] = "wilcoxon",
    pts: bool = True,
    min_in_group_fraction: float = 0.5,
    max_out_group_fraction: float = 0.25,
    min_fold_change: float = 0.585,
    rawDt: dict = {},
    filterDt: dict = {},
):
    """
    Rank and filter genes for characterizing groups.

    Parameters
    ----------
    adata : anndata.AnnData
        Expects logarithmized data.
    groupby : str
        The key of the observations grouping to consider.
    key_added : str
        The key in adata.uns information is saved to.
    groups : Union[Literal[, optional
        Subset of groups, e.g. ['g1', 'g2', 'g3'], to which comparison shall be restricted, or 'all' (default), for all groups.
        Function also is supported. e.g. lambda x: x!='g1'
        Defaults to "all".
    use_raw : bool, optional
        by default False.
    layer: Optional, str.
        use which matrix as the used expression matrix. it takes precedence of use_raw.
    method : Literal[, optional
        't-test', 't-test_overestim_var' overestimates variance of each group,
        'wilcoxon' uses Wilcoxon rank-sum,
        'logreg' uses logistic regression.
        Defaults to "wilcoxon".
    pts : bool, optional
        Compute the fraction of cells expressing the genes. Defaults to True.
    min_in_group_fraction : float, optional
        by default 0.5
    max_out_group_fraction : float, optional
        by default 0.25
    min_fold_change : float, optional
        by default 2
    rawDt : dict, optional
        Other parameters for sc.tl.rank_genes_groups. Defaults to {}.
    filterDt : dict, optional
        ther parameters for sc.tl.filter_rank_genes_groups. Defaults to {}.
    """
    if groups != "all":
        if isinstance(groups, Callable):
            allCategoriesSq = adata.obs[groupby].astype("category").cat.categories
            groups = allCategoriesSq[allCategoriesSq.map(groups)]
            groups = list(groups)

        _adata = adata[adata.obs.query(f"{groupby} in @groups").index]
    else:
        _adata = adata

    rawDt = dict(
        groupby=groupby,
        groups=groups,
        use_raw=use_raw,
        layer=layer,
        method=method,
        pts=pts,
        key_added=key_added,
        **rawDt,
    )
    filterDt = dict(
        key=key_added,
        key_added=f"{key_added}_filtered",
        min_in_group_fraction=min_in_group_fraction,
        max_out_group_fraction=max_out_group_fraction,
        min_fold_change=min_fold_change,
        **filterDt,
    )

    sc.tl.rank_genes_groups(_adata, **rawDt)
    sc.tl.filter_rank_genes_groups(_adata, **filterDt)
    if groups != "all":
        adata.uns[key_added] = _adata.uns[key_added]
        adata.uns[f"{key_added}_filtered"] = _adata.uns[f"{key_added}_filtered"]


def calculateEnrichScoreByCellex(
    adata: anndata.AnnData,
    layer: Optional[str] = None,
    clusterName: str = "leiden",
    batchKey: Optional[str] = None,
    copy: bool = False,
    kayAddedPrefix: Optional[str] = None,
    dt_kwargsForCellex: dict = {},
) -> Optional[anndata.AnnData]:
    """
    calculateEnrichScoreByCellex

    Parameters
    ----------
    adata : anndata.AnnData
    layer : Optional[str], optional
        Must be int, by default None
    clusterName : str, optional
        by default 'leiden'
    copy : bool, optional
        by default False

    Returns
    -------
    anndata if copy else None
    """
    import cellex

    def _singleBatch(adata, layer, clusterName, kayAddedPrefix, dt_kwargsForCellex):
        # df_mtx = adata.to_df(layer).T if layer else adata.to_df().T
        df_mtx = basic.ad2df(adata, layer=layer, forceDense=True).T
        df_meta = adata.obs[[clusterName]].rename({clusterName: "cell_type"}, axis=1)
        eso = cellex.ESObject(data=df_mtx, annotation=df_meta, **dt_kwargsForCellex)
        eso.compute()
        mtx_enrichScore = eso.results["esmu"].reindex(adata.var.index).fillna(0)
        adata.varm[f"{kayAddedPrefix}_cellexES"] = mtx_enrichScore

        mtx_geneExpRatio = (
            basic.ad2df(adata, layer=layer)
            .groupby(adata.obs[clusterName])
            .apply(lambda df: (df > 0).mean())
            .T
        )
        df_geneExpRatio = (
            mtx_geneExpRatio.rename_axis(index="gene", columns=clusterName)
            .melt(ignore_index=False, value_name="expressed_ratio")
            .reset_index()
        )

        ls_cluster = adata.obs[clusterName].unique()
        # mtx_binary = (adata.to_df(layer) > 0).astype(int)

        # dt_geneExpRatioOtherCluster = {}
        # for cluster in ls_cluster:
        #     ls_index = adata.obs[clusterName].pipe(lambda sr: sr[sr != cluster]).index
        #     dt_geneExpRatioOtherCluster[cluster] = mtx_binary.loc[ls_index].mean(0)

        dt_geneExpRatioOtherCluster = {}
        for cluster in ls_cluster:
            ls_index = adata.obs[clusterName].pipe(lambda sr: sr[sr != cluster]).index
            _ad = adata[ls_index]
            _ar = (_ad.layers[layer] > 0).mean(0)
            if isinstance(_ar, np.matrix):
                _ar = _ar.A1
            dt_geneExpRatioOtherCluster[cluster] = pd.Series(_ar, index=_ad.var.index)

        mtx_geneExpRatioOtherCluster = pd.DataFrame.from_dict(
            dt_geneExpRatioOtherCluster
        )
        df_geneExpRatioOtherCluster = (
            mtx_geneExpRatioOtherCluster.rename_axis(index="gene", columns=clusterName)
            .melt(ignore_index=False, value_name="expressed_ratio_others")
            .reset_index()
        )

        df_result = (
            mtx_enrichScore.rename_axis(index="gene", columns=clusterName)
            .melt(ignore_index=False, value_name="enrichScore")
            .reset_index()
            .merge(
                df_geneExpRatio,
                left_on=["gene", clusterName],
                right_on=["gene", clusterName],
            )
            .merge(
                df_geneExpRatioOtherCluster,
                left_on=["gene", clusterName],
                right_on=["gene", clusterName],
            )
        )

        _lsSr = []
        for key, _df in eso.results.items():
            _ls = key.split('.')
            if len(_ls) == 1:
                continue
            method, attr = _ls
            if attr not in ['pvals', 'esw_s']:
                continue
            _lsSr.append(_df.stack().rename(f"{method}_{attr}"))
        # import pdb; pdb.set_trace()  # XXX BREAKPOINT
        df_others = pd.concat(_lsSr,axis=1).reset_index().rename({'level_0': 'gene', 'level_1': clusterName}, axis=1)
        df_others['significantCounts'] = (df_others.filter(like='pvals') < 0.05).sum(1)
        df_result = df_result.merge(df_others, left_on=['gene', clusterName], right_on=['gene', clusterName], how='left')
        df_result[clusterName] = df_result[clusterName].astype('category').cat.set_categories(ls_cluster)
        # adata.uns[f"{kayAddedPrefix}_cellex_all"] = df_others.copy()

        adata.uns[f"{kayAddedPrefix}_cellexES"] = df_result.copy()

    adata.var = adata.var.rename_axis(index=None)
    adata = adata.copy() if copy else adata
    basic.testAllCountIsInt(adata, layer)

    if kayAddedPrefix is None:
        kayAddedPrefix = clusterName

    if layer == "X":
        layer = None
    if batchKey is None:
        _singleBatch(adata, layer, clusterName, kayAddedPrefix, dt_kwargsForCellex)
    else:
        ls_batchAd = basic.splitAdata(adata, batchKey, needName=True)
        adata.uns[f"{kayAddedPrefix}_cellexES"] = {}
        for sample, ad_batch in ls_batchAd:
            _singleBatch(
                ad_batch, layer, clusterName, kayAddedPrefix, dt_kwargsForCellex
            )
            adata.uns[f"{kayAddedPrefix}_cellexES"][sample] = ad_batch.uns[
                f"{kayAddedPrefix}_cellexES"
            ]

    if copy:
        return adata


def getMarkerFromCellexResults(
    ad,
    clusterName,
    minCounts,
    filterExpr="enrichScore > 0.9 & expressed_ratio > 0.1 & expressed_ratio_others < 0.1",
):
    from functools import reduce

    _ls = []
    lsDf_Concat = []
    for sample, df_geneInfo in ad.uns[f"{clusterName}_cellexES"].items():
        _ls.append(df_geneInfo.query(filterExpr)[["gene", clusterName]])
        lsDf_Concat.append(
            df_geneInfo.rename(
                columns=lambda x: f"{sample}_{x}"
                if x in ["enrichScore", "expressed_ratio", "expressed_ratio_others"]
                else x
            )
        )
    sr_geneCounts = (
        pd.concat(_ls).value_counts().rename("counts").pipe(pd.DataFrame).reset_index()
    )
    df_results = reduce(
        lambda x, y: pd.merge(
            x,
            y,
            left_on=("gene", clusterName),
            right_on=("gene", clusterName),
            how="outer",
        ),
        [sr_geneCounts, *lsDf_Concat],
    ).query("counts >= @minCounts")
    df_results.insert(
        3,
        "mean_expressed_ratio_others",
        df_results.filter(like="expressed_ratio_others").mean(1),
    )
    df_results.insert(
        3, "mean_expressed_ratio", df_results.filter(like="expressed_ratio").mean(1)
    )
    df_results.insert(
        3, "mean_enrichScore", df_results.filter(like="enrichScore").mean(1)
    )
    df_results = df_results.sort_values(
        [clusterName, "mean_enrichScore"], ascending=[True, False]
    )
    return df_results


def getEnrichedGeneByCellId(
    adata: anndata.AnnData,
    layer: Optional[str] = None,
    clusterName: str = "leiden",
    n_features: int = 200,
    nmcs: int = 50,
    copy: bool = False,
    returnR: bool = False,
    layerScaled: bool = False,
) -> Optional[pd.DataFrame]:
    """
    use CelliD get enriched gene

    Parameters
    ----------
    adata : anndata.AnnData
    layer : Optional[str], optional
        must be log-transformed data, by default None
    clusterName : str, optional
        by default 'leiden'
    n_features : int, optional
        by default 200
    copy : bool, optional
        by default False
    returnR : bool, optional
        This parameter takes precedence over copy. by default False.

    Returns
    -------
    Optional[pd.DataFrame]
        if copy, dataframe will be returned, else the anndata will be updated by following rules:
            obsm/varm will be updated by mca.
            uns will be updated by cellid_marker
    """
    import rpy2.robjects as ro
    from rpy2.robjects.packages import importr
    from ..rTools import py2r, r2py

    rBase = importr("base")
    cellId = importr("CelliD")
    R = ro.r
    _ad = basic.getPartialLayersAdata(adata, [layer], [clusterName])
    if not layerScaled:
        sc.pp.scale(_ad, layer=layer, max_value=10)
    adataR = py2r(_ad)
    adataR = cellId.RunMCA(adataR, slot=layer, nmcs=nmcs)
    VectorR_marker = cellId.GetGroupGeneSet(
        adataR,
        group_by=clusterName,
        n_features=n_features,
        dims=py2r(np.arange(1, 1 + nmcs)),
    )
    if returnR:
        return VectorR_marker

    df_marker = r2py(rBase.data_frame(VectorR_marker, check_names=False))
    if copy:
        return df_marker
    else:
        adata.obsm["mca"] = r2py(
            rBase.as_data_frame(
                R.reducedDim(adataR, "MCA"),
            )
        )
        adata.varm["mca"] = r2py(
            rBase.as_data_frame(R.attr(R.reducedDim(adataR, "MCA"), "genesCoordinates"))
        ).reindex(adata.var.index, fill_value=0)
        adata.uns[f"{clusterName}_cellid_marker"] = df_marker


def getMarkerByFcCellexCellidDiffxpy(
    adata: anndata.AnnData,
    normalize_layer: str,
    raw_layer: str,
    groupby: str,
    groups: List[str] = None,
    forceAllRun: bool = False,
    dt_ByFcParams={},
    dt_DiffxpyParams={},
    dt_DiffxpyGetMarkerParams={},
    cutoff_cellex: float = 0.9,
    markerCounts_CellId: int = 50,
):
    """
    use three method to identify markers

    Parameters
    ----------
    adata : anndata.AnnData
    normalize_layer : str
        must be log-transformed
    raw_layer : str
        must be integer
    groupby : str
        column name in adata.obs
    groups : List[str], optional
        Only use these clusters, by default None
    forceAllRun : bool, optional
        by default False
    dt_ByFcParams : dict, optional
        params transfered to `geneEnrichInfo.detectMarkerGene`, by default {}
    dt_DiffxpyParams : dict, optional
        params transfered to `diffxpy.vsRest`, by default {}
    dt_DiffxpyGetMarkerParams : dict, optional
        params transfered to `diffxpy.getMarker`, by default {"detectedCounts":-2)}
    cutoff_cellex : float, optional
        by default 0.9
    markerCounts_CellId : int, optional
        by default 50
    """
    from itertools import product
    import scipy.sparse as ss
    import upsetplot
    import matplotlib.pyplot as plt

    adata.uns[f"marker_multiMethod_{groupby}"] = {}
    if not groups:
        groups = list(adata.obs[groupby].unique())

    ad_sub = adata[adata.obs.eval(f"{groupby} in @groups")].copy()
    # ad_sub.layers[f"{layer}_raw"] = (
    #     np.around(np.exp(ad_sub.layers[layer].A) - 1)
    #     if ss.issparse(ad_sub.layers[layer])
    #     else np.around(np.exp(ad_sub.layers[layer]) - 1)
    # )

    ## fc method
    if forceAllRun | (f"{groupby}_fcMarker" not in ad_sub.uns):
        detectMarkerGene(
            ad_sub,
            groupby,
            f"{groupby}_fcMarker",
            layer=normalize_layer,
            **dt_ByFcParams,
        )
        adata.uns[f"{groupby}_fcMarker"] = ad_sub.uns[f"{groupby}_fcMarker"]
        adata.uns[f"{groupby}_fcMarker_filtered"] = ad_sub.uns[
            f"{groupby}_fcMarker_filtered"
        ]
    dt_markerByFc = (
        sc.get.rank_genes_groups_df(ad_sub, None, key=f"{groupby}_fcMarker_filtered")
        .groupby("group")["names"]
        .agg(list)
        .to_dict()
    )
    adata.uns[f"marker_multiMethod_{groupby}"]["fcMarker"] = dt_markerByFc

    ## cellex method
    if forceAllRun | (f"{groupby}_cellexES" not in ad_sub.varm):
        calculateEnrichScoreByCellex(ad_sub, f"{raw_layer}", groupby)
        adata.varm[f"{groupby}_cellexES"] = ad_sub.varm[f"{groupby}_cellexES"]
    dt_marker_cellex = (
        ad_sub.varm[f"{groupby}_cellexES"]
        .apply(lambda x: list(x[x > cutoff_cellex].sort_values(ascending=False).index))
        .to_dict()
    )
    adata.uns[f"marker_multiMethod_{groupby}"]["cellexMarker"] = dt_marker_cellex

    ## cellid method
    if forceAllRun | (f"{groupby}_cellid_marker" not in adata.uns):
        getEnrichedGeneByCellId(ad_sub, normalize_layer, groupby, markerCounts_CellId)
        adata.uns[f"{groupby}_cellid_marker"] = ad_sub.uns[f"{groupby}_cellid_marker"]
    dt_markerCellId = {
        x: list(y)
        for x, y in ad_sub.uns[f"{groupby}_cellid_marker"].to_dict("series").items()
    }

    adata.uns[f"marker_multiMethod_{groupby}"]["cellidMarker"] = dt_markerCellId

    ## diffxpy method
    if forceAllRun | (f"{groupby}_diffxpy_marker" not in adata.uns):
        diffxpy.vsRest(
            ad_sub,
            raw_layer,
            groupby,
            keyAdded=f"{groupby}_diffxpy_marker",
            inputIsLog=False,
            **dt_DiffxpyParams,
        )
        adata.uns[f"{groupby}_diffxpy_marker"] = ad_sub.uns[f"{groupby}_diffxpy_marker"]

    df_diffxpyMarker = diffxpy.getMarker(
        adata, key=f"{groupby}_diffxpy_marker", **dt_DiffxpyGetMarkerParams
    )
    adata.uns[f"marker_multiMethod_{groupby}"]["diffxpyMarker"] = (
        df_diffxpyMarker.groupby("clusterName")["gene"].agg(list).to_dict()
    )

    # concat
    for markerCat, cluster in product(
        ["fcMarker", "cellexMarker", "cellidMarker", "diffxpyMarker"], groups
    ):
        if cluster not in adata.uns[f"marker_multiMethod_{groupby}"][markerCat]:
            adata.uns[f"marker_multiMethod_{groupby}"][markerCat][cluster] = []

    ls_allClusterMarker = []
    for cluster in groups:
        ls_clusterMarker = [
            y
            for x in ["fcMarker", "cellexMarker", "cellidMarker", "diffxpyMarker"]
            for y in adata.uns[f"marker_multiMethod_{groupby}"][x][cluster]
        ]

        ls_clusterMarker = list(set(ls_clusterMarker))
        ls_clusterName = [cluster] * len(ls_clusterMarker)
        df_clusterMarker = pd.DataFrame(
            [ls_clusterName, ls_clusterMarker], index=["cluster", "marker"]
        ).T
        df_clusterMarker = df_clusterMarker.pipe(
            lambda df: df.assign(
                fcMarker=df["marker"].isin(
                    adata.uns[f"marker_multiMethod_{groupby}"]["fcMarker"][cluster]
                ),
                cellexMarker=df["marker"].isin(
                    adata.uns[f"marker_multiMethod_{groupby}"]["cellexMarker"][cluster]
                ),
                cellidMarker=df["marker"].isin(
                    adata.uns[f"marker_multiMethod_{groupby}"]["cellidMarker"][cluster]
                ),
                diffxpyMarker=df["marker"].isin(
                    adata.uns[f"marker_multiMethod_{groupby}"]["diffxpyMarker"][cluster]
                ),
            ).assign(
                detectedMethodCounts=lambda df: df[
                    ["fcMarker", "cellexMarker", "cellidMarker", "diffxpyMarker"]
                ].sum(1)
            )
        )
        ls_allClusterMarker.append(df_clusterMarker)
    df_allClusterMarker = pd.concat(ls_allClusterMarker)
    adata.uns[f"marker_multiMethod_{groupby}"]["unionInfo"] = df_allClusterMarker

    axs = upsetplot.plot(
        df_allClusterMarker[
            ["fcMarker", "cellexMarker", "cellidMarker", "diffxpyMarker"]
        ].value_counts(),
        sort_by="cardinality",
    )
    plt.sca(axs["intersections"])
    plt.yscale("log")


def getDEGByScvi(
    ad: sc.AnnData,
    path_model: Optional[Union[str, scvi.model.SCVI]],
    layer: Optional[str],
    groupby: str,
    batchKey: Optional[str] = None,
    correctBatch: bool = True,
    minCells: int = 10,
    threads: int = 36,
    keyAdded: Optional[str] = "marker_byScvi",
    only_train_model: bool = False,
    batch_size=512,
) -> Tuple[scvi.model.SCVI, pd.DataFrame]:
    """[summary]

    Parameters
    ----------
    ad : sc.AnnData
    path_model : Optional[str]
        stored path of trained scvi.model.SCVI or scvi.model.SCVI
    layer : Optional[str]
        must be raw
    groupby : str
        cluster key
    batchKey : Optional[str]
        batch key
    correctBatch : bool, optional
        by default True
    minCells : int, optional
        by default 10
    threads : int, optional
        by default 36
    keyAdded : Optional[str], optional
        if None, adata will not be updated, by default "marker_byScvi"

    Returns
    -------
    Tuple[scvi.model.SCVI, pd.DataFrame]
    """
    scvi.settings.seed = 39
    scvi.settings.num_threads = threads

    layer = None if layer == "X" else layer
    ad.X = ad.layers[layer].copy()
    ad_forDE = sc.pp.filter_genes(ad, min_cells=minCells, copy=True)
    scvi.model.SCVI.setup_anndata(
        ad_forDE,
        layer=None,
        batch_key=batchKey,
    )

    if not path_model:
        scvi_model = scvi.model.SCVI(ad_forDE)
        scvi_model.train(early_stopping=True, batch_size=batch_size)
        scvi_model.history["elbo_train"].plot()
        plt.yscale("log")
        plt.show()

    else:
        if isinstance(path_model, str):
            scvi_model = scvi.model.SCVI.load(path_model, ad_forDE)
        elif isinstance(path_model, scvi.SCVI.model):
            scvi_model = path_model
        else:
            assert False, f"Unknown data type: {type(path_model)}"

    if only_train_model:
        return scvi_model, None

    df_deInfo = scvi_model.differential_expression(
        ad_forDE, groupby=groupby, batch_correction=correctBatch
    )
    if not keyAdded:
        pass
    else:
        keyAdded = keyAdded + "_" + groupby
        ad.uns[keyAdded] = df_deInfo

    return scvi_model, df_deInfo


def getDEGFromScviResult(
    adata,
    df_deInfo,
    groupby,
    groups=None,
    bayesCutoff=3,
    nonZeroProportion=0.1,
    markerCounts=None,
    keyAdded=None,
):
    adata.obs[groupby] = adata.obs[groupby].astype("category")
    if not groups:
        cats = list(adata.obs[groupby].cat.categories)

    markers = {}
    cats = adata.obs[groupby].cat.categories
    for i, c in enumerate(cats):
        cid = "{} vs Rest".format(c)
        cell_type_df = df_deInfo.loc[df_deInfo.comparison == cid]

        cell_type_df = cell_type_df[cell_type_df.lfc_mean > 0]

        cell_type_df = cell_type_df[cell_type_df["bayes_factor"] > bayesCutoff]
        cell_type_df = cell_type_df[
            cell_type_df["non_zeros_proportion1"] > nonZeroProportion
        ]
        if not markerCounts:
            markers[c] = cell_type_df.index.tolist()
        else:
            markers[c] = cell_type_df.index.tolist()[:markerCounts]

    if not keyAdded:
        keyAdded = f"scvi_marker_{groupby}"
    adata.uns[keyAdded] = markers


def getCosgResult(ad, key="cosg") -> pd.DataFrame:
    """
    maybe the SOTA algorithm for one batch datasets
    """
    df = (
        pd.concat(
            [
                pd.DataFrame(ad.uns[key]["names"]).stack().rename("name"),
                pd.DataFrame(ad.uns[key]["scores"]).stack().rename("score"),
            ],
            axis=1,
        )
        .reset_index(level=0, drop=True)
        .rename_axis("cluster")
        .reset_index()
        .sort_values(["cluster", "score"], ascending=[True, False])
    )
    return df


def getAUCellScore(
    ad,
    dt_genes,
    layer,
    threads=1,
    aucMaxRank=500,
    aucMaxPropotion=None,
    label="AUCell",
    calcThreshold=False,
    thresholdsHistCol=5,
    dt_kwargs2aucell={},
    chunksize=10000,
    **dt_kwargs,
):
    '''It takes a list of gene sets, and calculates the AUCell score for each gene set

    Parameters
    ----------
    ad
        AnnData object
    dt_genes
        a dictionary of gene sets. The keys are the names of the gene sets, and the values are lists of gene names.
    layer
        the name of the layer to use for the AUCell calculation.
    threads, optional
        number of threads to use
    aucMaxRank, optional
        the maximum rank of genes used for calculating AUCell score.
    aucMaxPropotion
        same as aucMaxRank.
    label, optional
        the name of the column in ad.obsm that will contain the AUCell scores
    calcThreshold, optional
        whether to calculate the threshold for binarization
    thresholdsHistCol, optional
        the number of columns in the histogram of thresholds
    dt_kwargs2aucell
        parameters for the aucell function

    '''
    from pyscenic.transform import df2regulons
    from pyscenic.aucell import aucell
    from pyscenic.plotting import plot_binarization
    from pyscenic.binarization import binarize

    assert not (aucMaxRank is None) & (
        aucMaxPropotion is None
    ), "Either aucMaxRank or aucMaxPropotion must be specified"
    assert not (
        (not aucMaxRank is None) & (not aucMaxPropotion is None)
    ), "aucMaxRank and aucMaxPropotion cannot be specified at the same time"
    if not aucMaxRank is None:
        aucMaxPropotion = aucMaxRank / ad.shape[1]

    df_pseudoMotif = pd.DataFrame(
        columns=[
            "TF",
            "MotifID",
            "AUC",
            "Annotation",
            "Context",
            "MotifSimilarityQvalue",
            "NES",
            "OrthologousIdentity",
            "RankAtMax",
            "TargetGenes",
            "MotifLogo",
        ]
    )
    for geneSetName, ls_gene in dt_genes.items():
        _sr = pd.Series(
            [
                geneSetName,
                geneSetName,
                np.nan,
                geneSetName,
                (np.nan,),
                np.nan,
                np.nan,
                np.nan,
                np.nan,
                [(x, 1) for x in ls_gene],
                np.nan,
            ],
            [
                "TF",
                "MotifID",
                "AUC",
                "Annotation",
                "Context",
                "MotifSimilarityQvalue",
                "NES",
                "OrthologousIdentity",
                "RankAtMax",
                "TargetGenes",
                "MotifLogo",
            ],
        )
        df_pseudoMotif.loc[df_pseudoMotif.shape[0]] = _sr
    ls_reg = (
        df2regulons(df_pseudoMotif)
        >> F(map, lambda x: x.rename(x.transcription_factor))
        >> F(list)
    )

    if chunksize is None:
        df_mtx = basic.ad2df(ad, layer)
        df_auc = aucell(
            df_mtx,
            signatures=ls_reg,
            auc_threshold=aucMaxPropotion,
            num_workers=threads,
            noweights=True,
            seed=0,
            **dt_kwargs2aucell,
        )
    else:
        maxIter = int(np.ceil(ad.shape[0] / chunksize))
        lsDf_auc = []
        for i in tqdm(range(0, ad.shape[0], chunksize)):
            _df_mtx = basic.ad2df(ad[i:i+chunksize], layer)
            # _df_mtx = _df_mtx.iloc[i:i+chunksize]
            _df_auc = aucell(
                _df_mtx,
                signatures=ls_reg,
                auc_threshold=aucMaxPropotion,
                num_workers=threads,
                noweights=True,
                seed=0,
                **dt_kwargs2aucell,
            )
            lsDf_auc.append(_df_auc)
            import gc;gc.collect()
        df_auc = pd.concat(lsDf_auc)

    # import pdb;pdb.set_trace()
    ad.obsm[label] = df_auc.reindex(ad.obs.index)

    if calcThreshold:
        df_binary, sr_aucThresholds = binarize(df_auc, seed=0, num_workers=threads)
        lsBk = []
        for geneSetName in dt_genes.keys():
            bk = pw.Brick(figsize=(3, 2))
            plot_binarization(df_auc, geneSetName, sr_aucThresholds[geneSetName], ax=bk)
            plt.close()
            lsBk.append(bk)
        bk = pwStack(lsBk, thresholdsHistCol)
        pwShow(bk)

        ad.uns[label] = sr_aucThresholds.to_dict()
        ad.obsm[f"{label}_binary"] = df_binary.reindex(ad.obs.index)


@rcontext
def getAUCellScore_r(
    ad,
    dt_genes,
    layer,
    threads=1,
    aucMaxRank=500,
    label="AUCell",
    thresholdsHistCol=3,
    show=False,
    forceDense=False,
    rEnv=None,
):
    """

    Parameters
    ----------
    ad :
    dt_genes :
    layer :
        rank based
    label : str, optional
        by default 'AUCell'
    rEnv: ro.Environment
        by default None
    """
    from math import ceil
    import rpy2
    import rpy2.robjects as ro
    from rpy2.robjects.packages import importr
    import scipy.sparse as ss
    from ..rTools import py2r, r2py, r_inline_plot, rHelp, trl, rSet, rGet, ad2so, so2ad

    rBase = importr("base")
    rUtils = importr("utils")
    dplyr = importr("dplyr")
    reticulate = importr("reticulate")
    R = ro.r

    aucell = importr("AUCell")

    def getThreshold(objR_name, geneCate):
        # print(f"as.data.frame({objR_name}${geneCate}$aucThr$thresholds)")
        df = r2py(R(f"as.data.frame({objR_name}$`{geneCate}`$aucThr$thresholds)"))
        df = df.assign(geneCate=geneCate)
        return df

    thresholdsHistRow = ceil(len(dt_genes) / thresholdsHistCol)
    ls_varName = ad.var.index.to_list()
    ls_obsName = ad.obs.index.to_list()
    mtx = ad.layers[layer].T
    if ss.issparse(mtx) & forceDense:
        mtx = mtx.A
    mtxR = py2r(mtx)
    del mtx

    fc_list2R = lambda x: R.unlist(R.list(x))
    lsR_obsName = fc_list2R(ls_obsName)
    lsR_varName = fc_list2R(ls_varName)
    dtR_genes = R.list(**{x: fc_list2R(y) for x, y in dt_genes.items()})

    rEnv["mtxR"] = mtxR
    rEnv["lsR_obsName"] = lsR_obsName
    rEnv["lsR_varName"] = lsR_varName
    rEnv["dtR_genes"] = dtR_genes
    rEnv["threads"] = threads
    rEnv["aucMaxRank"] = aucMaxRank
    rEnv["thresholdsHistCol"] = thresholdsHistCol
    rEnv["thresholdsHistRow"] = thresholdsHistRow
    with r_inline_plot():
        R(
            """
        rownames(mtxR) <- lsR_varName
        colnames(mtxR) <- lsR_obsName
        cells_rankings <- AUCell_buildRankings(mtxR, nCores=threads, plotStats=TRUE)
        cells_AUC <- AUCell_calcAUC(dtR_genes, cells_rankings, aucMaxRank=aucMaxRank)
        """
        )
    if show:
        with r_inline_plot(width=512):
            R(
                """
            par(mfrow=c(thresholdsHistRow, thresholdsHistCol)) 
            cells_assignment <- AUCell_exploreThresholds(cells_AUC, plotHist=T) 
            """
            )
    else:
        R(
            """
        cells_assignment <- AUCell_exploreThresholds(cells_AUC, plotHist=F) 
        """
        )
    df_auc = r2py(R("as.data.frame(cells_AUC@assays@data$AUC)")).T
    df_aucThreshold = pd.concat(
        [getThreshold("cells_assignment", x) for x in dt_genes.keys()]
    )
    ad.obsm[label] = df_auc.copy()
    ad.uns[label] = df_aucThreshold.copy()


def _getMetaCells(
    ad, ls_obs, layer="raw", skipSmallGroup=True, target_metacell_size=5e4, verbose=True, **kwargs
):
    """
    get meta-cell from adata
    """
    import metacells as mc

    if isinstance(ls_obs, str):
        ls_obs = [ls_obs]
    dtAd_meta = {}
    ls_changeObs = []
    for ls_label, df in ad.obs.groupby(ls_obs):
        if isinstance(ls_label, str):
            ls_label = [ls_label]

        ad_sub = ad[df.index].copy()
        ad_sub.X = ad_sub.layers[layer].copy()
        logger.info(f"{ls_label} info:: {len(ad_sub)} cells, {ad_sub.X.sum()} UMIs")

        if ad_sub.X.sum() / 2 < target_metacell_size:
            ls_changeObs.append(ls_label)
            if skipSmallGroup:
                logger.warning(f"{ls_label} is too small, skip")
                continue
            else:
                _target_metacell_size = ad_sub.X.sum() // 2
                logger.warning(
                    f"{ls_label} is too small, set target_metacell_size to {_target_metacell_size}"
                )
                with MuteInfo(verbose):
                    mc.pl.divide_and_conquer_pipeline(
                        ad_sub, target_metacell_size=_target_metacell_size, **kwargs
                    )
        else:
            with MuteInfo(verbose):
                mc.pl.divide_and_conquer_pipeline(
                    ad_sub, target_metacell_size=target_metacell_size, **kwargs
                )
        with MuteInfo(verbose):
            ad_subMeta = mc.pl.collect_metacells(ad_sub, name="metacells")
        dt_metaLinkWithOrg = (
            ad_sub.obs["metacell"]
            .groupby(ad_sub.obs["metacell"])
            .apply(lambda sr: sr.index.to_list())
            .to_dict()
        )
        ad_subMeta.obs["metacell_link"] = ad_subMeta.obs.index.map(
            lambda x: dt_metaLinkWithOrg[int(x)]
        )

        # ad_sub.obs.index = ad_sub.obs.index.astype(str) + '-' + '-'.join(ls_label)
        for obsName, label in zip(ls_obs, ls_label):
            ad_subMeta.obs[obsName] = label
        ad_subMeta.layers[layer] = ad_subMeta.X.copy()
        dtAd_meta["-".join(ls_label)] = ad_subMeta
    ad_meta = sc.concat(dtAd_meta, index_unique="-")
    for obsName in ls_obs:
        if isinstance(ad.obs[obsName].dtype, pd.CategoricalDtype):
            ad_meta.obs[obsName] = (
                ad_meta.obs[obsName]
                .astype("category")
                .cat.reorder_categories(ad.obs[obsName].cat.categories)
            )
    ad_meta.obs["metacell_link"] = ad_meta.obs["metacell_link"].str.join(",")
    print(ad_meta.obs[ls_obs].value_counts())
    print(f"These {ls_changeObs} groups are skipped or changed due to small size")
    sns.histplot(ad_meta.to_df(layer).sum(1))
    plt.xlabel("metacell UMI counts")
    plt.show()

    sns.histplot(ad_meta.obs["metacell_link"].str.split(",").map(len))
    plt.xlabel("metacell cell counts")
    plt.show()
    return ad_meta


def scWGCNA(
    ad: sc.AnnData,
    layer: str,
    ls_obs: List,
    skipSmallGroup: bool,
    target_metacell_size: int,
    dir_result: str,
    jobid: str,
    ls_hvgGene: List[str],
    minModuleSize: int = 50,
    deepSplit: float = 4,
    mergeCutHeight: float = 0.2,
    threads: int = 1,
    softPower: Optional[Union[int, Literal["auto"]]] = None,
    renv=None,
    dt_getMetaCellsKwargs: dict = {},
    fc_autoPickSoftPower=lambda x: x["SFT.R.sq"] >= 0.8,
    calcAucell=True,
) -> sc.AnnData:
    """`scWGCNA` is a function that takes in a single cell RNA-seq dataset, and returns a single cell
    RNA-seq dataset with metacells

    Parameters
    ----------
    ad : sc.AnnData
        sc.AnnData
    layer : str
        str， 'raw'
    ls_obs : List
    skipSmallGroup : bool
        if True, skip the small groups in metacell construction step
    target_metacell_size : int
        the target size of metacells.
    dir_result : str
        str, store `blockwiseConsensusModules` results
    jobid : str
        str
    ls_hvgGene : List[str]
        List[str]
    minModuleSize : int, optional
        minimum number of genes in a module
    deepSplit : float, optional
        the number of times to split the dendrogram.
    mergeCutHeight : float
        the height of the merge cut.
    threads : int, optional
        number of threads to use
    softPower : Optional[Union[int, Literal['auto']]]
        The soft power parameter for WGCNA. If None, it will be manually picked; if 'auto', it will be automatically picked.
    renv
        R environment to use. If None, will use the default R environment.
    dt_getMetaCellsKwargs : dict
        dict = {}
    fc_autoPickSoftPower
        function to pick the soft power. columns: ['SFT.R.sq', 'mean.k.']. By default, it will pick the soft power if the 'SFT.R.sq' is greater than 0.8 (lambda x:x['SFT.R.sq'] >= 0.8).

    ---
    sc.AnnData
        with WGCNA results
    """
    import rpy2
    import rpy2.robjects as ro
    from rpy2.robjects.packages import importr
    from . import plotting
    from ..rTools import py2r, r2py, r_inline_plot, rHelp, trl, rGet, rSet, ad2so, so2ad
    import os
    import warnings

    os.environ["OPENBLAS_NUM_THREADS"] = "1"

    rBase = importr("base")
    rUtils = importr("utils")
    tidyverse = importr("tidyverse")
    WGCNA = importr("WGCNA")
    seurat = importr("Seurat")
    gplots = importr("gplots")
    R = ro.r
    R(f"disableWGCNAThreads()")

    if renv is None:
        renv = ro.Environment()

    # rlc = ro.local_context(renv)
    # rlc.__enter__()
    with ro.local_context(renv) as rlc:
        rlc["minModuleSize"] = minModuleSize
        rlc["deepSplit"] = deepSplit
        rlc["mergeCutHeight"] = mergeCutHeight
        rlc["maxBlockSize"] = len(ls_hvgGene)
        rlc["jobid"] = jobid
        rlc["dir_result"] = dir_result
        ls_removeGene = [x for x in ad.var.index.to_list() if x not in ls_hvgGene]
        ad_meta = _getMetaCells(
            ad,
            ls_obs,
            layer=layer,
            skipSmallGroup=skipSmallGroup,
            target_metacell_size=target_metacell_size,
            forbidden_gene_names=ls_removeGene,
            **dt_getMetaCellsKwargs,
        )[:, ls_hvgGene]
        # ad_meta = ad[:, ls_hvgGene].copy()
        basic.initLayer(ad_meta, layer=layer, total=1e6)
        datExpr = py2r(ad_meta.to_df("normalize_log"))
        rlc["datExpr"] = datExpr
        # import pdb; pdb.set_trace()
        R(
            """
        datExpr <- datExpr[,goodGenes(datExpr)]
        lsR_useGene = colnames(datExpr)
        """
        )

        if (softPower is None) | (softPower == "auto"):
            with r_inline_plot(width=768):
                R(
                    """
                powers = c(seq(1,10,by=1), seq(12,20, by=2))
                powerTable = list(
                data = pickSoftThreshold(
                    datExpr,
                    powerVector=powers,
                    verbose = 100,
                    networkType="signed",
                    corFnc="bicor"
                )[[2]]
                )

                # Plot the results:

                colors = c("blue", "red","black")
                # Will plot these columns of the returned scale free analysis tables
                plotCols = c(2,5,6,7)
                colNames = c("Scale Free Topology Model Fit", "Mean connectivity", "Median connectivity",
                "Max connectivity");

                # Get the minima and maxima of the plotted points
                ylim = matrix(NA, nrow = 2, ncol = 4);
                for (col in 1:length(plotCols)){
                ylim[1, col] = min(ylim[1, col], powerTable$data[, plotCols[col]], na.rm = TRUE);
                ylim[2, col] = max(ylim[2, col], powerTable$data[, plotCols[col]], na.rm = TRUE);
                }
                """
                )
                # Plot the quantities in the chosen columns vs. the soft thresholding power
                R(
                    """
                par(mfcol = c(2,2));
                par(mar = c(4.2, 4.2 , 2.2, 0.5))
                cex1 = 0.7;

                for (col in 1:length(plotCols)){
                    plot(powerTable$data[,1], -sign(powerTable$data[,3])*powerTable$data[,2],
                    xlab="Soft Threshold (power)",ylab=colNames[col],type="n", ylim = ylim[, col],
                    main = colNames[col]);
                    addGrid();

                    if (col==1){
                        text(powerTable$data[,1], -sign(powerTable$data[,3])*powerTable$data[,2],
                        labels=powers,cex=cex1,col=colors[1]);
                    } else
                    text(powerTable$data[,1], powerTable$data[,plotCols[col]],
                    labels=powers,cex=cex1,col=colors[1]);
                    if (col==1){
                        legend("bottomright", legend = 'Metacells', col = colors, pch = 20) ;
                    } else
                    legend("topright", legend = 'Metacells', col = colors, pch = 20) ;
                }
                """
                )
            if softPower == "auto":
                df_powerTable = r2py(R("powerTable$data"))
                df_powerTable["Power"] = df_powerTable["Power"].astype(int)
                df_powerTable = df_powerTable.loc[fc_autoPickSoftPower]
                softPower = df_powerTable["Power"].min()
                logger.info(f"Soft Power: {softPower}")
            else:
                softPower = int(input("Soft Power"))
        rlc["softPower"] = int(softPower)

        if threads > 1:
            R(f"enableWGCNAThreads({threads})")
        else:
            R(f"disableWGCNAThreads()")

        R(
            """
        nSets = 1
        setLabels <- 'ODC'
        shortLabels <- setLabels

        multiExpr <- list()
        multiExpr[['ODC']] <- list(data=datExpr)
        checkSets(multiExpr) 

        net <- blockwiseConsensusModules(multiExpr, blocks = NULL,
                                                maxBlockSize = maxBlockSize, ## This should be set to a smaller size if the user has limited RAM
                                                randomSeed = 39,
                                                corType = "pearson",
                                                power = softPower,
                                                consensusQuantile = 0.3,
                                                networkType = "signed",
                                                TOMType = "unsigned",
                                                TOMDenom = "min",
                                                scaleTOMs = TRUE, scaleQuantile = 0.8,
                                                sampleForScaling = TRUE, sampleForScalingFactor = 1000,
                                                useDiskCache = TRUE, chunkSize = NULL,
                                                deepSplit = deepSplit,
                                                pamStage=FALSE,
                                                detectCutHeight = 0.995, minModuleSize = minModuleSize,
                                                mergeCutHeight = mergeCutHeight,
                                                saveConsensusTOMs = TRUE,
                                                consensusTOMFilePattern = paste0(dir_result, "/", jobid, "_TOM_block.%b.rda"))

        consMEs = net$multiMEs;
        moduleLabels = net$colors;

        # Convert the numeric labels to color labels
        moduleColors = as.character(moduleLabels)
        consTree = net$dendrograms[[1]];

        # module eigengenes
        MEs=moduleEigengenes(multiExpr[[1]]$data, colors = moduleColors, nPC=1)$eigengenes
        MEs=orderMEs(MEs)
        meInfo<-data.frame(rownames(datExpr), MEs)
        colnames(meInfo)[1]= "SampleID"

        # intramodular connectivity
        KMEs<-signedKME(datExpr, MEs,outputColumnName = "kME",corFnc = "bicor")

        # compile into a module metadata table
        geneInfo=as.data.frame(cbind(colnames(datExpr),moduleColors, KMEs))

        # how many modules did we get?
        nmodules <- length(unique(moduleColors))

        # merged gene symbol column
        colnames(geneInfo)[1]= "GeneSymbol"
        colnames(geneInfo)[2]= "Initially.Assigned.Module.Color"
        PCvalues=MEs
        """
        )

        with r_inline_plot(width=768):
            R(
                """
            plotDendroAndColors(consTree, moduleColors, "Module colors", dendroLabels = FALSE, hang = 0.03, addGuide = TRUE, guideHang = 0.05,
                                main = paste0("ODC lineage gene dendrogram and module colors"))"""
            )
        with r_inline_plot(width=768):
            R(
                """
            plotEigengeneNetworks(PCvalues, "Eigengene adjacency heatmap", 
                                marDendro = c(3,3,2,4),
                                marHeatmap = c(3,4,2,2), plotDendrograms = T, 
                                xLabelsAngle = 90)
            """
            )
        R(
            """
        load(paste0(dir_result, "/", jobid, "_TOM_block.1.rda"), verbose=T)

        probes = colnames(datExpr)
        TOM <- as.matrix(consTomDS)
        dimnames(TOM) <- list(probes, probes)

        # cyt = exportNetworkToCytoscape(TOM,
        #             weighted = TRUE, threshold = 0.1,
        #             nodeNames = probes, nodeAttr = moduleColors)
        """
        )

        ad_meta = ad_meta[:, list(rlc["lsR_useGene"])]
        ad_meta.obsm["eigengene"] = r2py(R("meInfo"))
        ad_meta.obsm["eigengene"].drop(columns="SampleID", inplace=True)
        ad_meta.varm["KME"] = r2py(R("geneInfo"))
        ad_meta.varp["TOM"] = r2py(R("TOM"))

        # cyt = R("cyt")
        # df_edge = r2py(rGet(cyt, "$edgeData"))
        # df_node = r2py(rGet(cyt, "$nodeData"))

        # dt_cyt = {"node": df_node, "edge": df_edge}
        # ad_meta.uns["cyt"] = dt_cyt
        ad_meta.uns[f"{jobid}_wgcna"] = {}
        ls_colorName = (
            ad_meta.varm["KME"]["Initially.Assigned.Module.Color"].unique().tolist()
        )
        dt_color = {x: gplots.col2hex(x)[0] for x in ls_colorName}
        ad_meta.uns[f"{jobid}_wgcna"]["colors"] = dt_color

        dt_moduleGene = (
            ad_meta.varm["KME"]
            .groupby("Initially.Assigned.Module.Color")
            .apply(lambda df: df.index.to_list())
            .to_dict()
        )
        ad_meta.uns[f"{jobid}_wgcna"]["genes"] = dt_moduleGene

        dt_moduleGene = {x: y for x, y in dt_moduleGene.items() if x != "grey"}
        axs = plotting.clustermap(
            ad_meta,
            dt_moduleGene,
            obsAnno=ls_obs,
            layer="normalize_log",
            #     standard_scale=1,
            space_obsAnnoLegend=0.3,
            cbarPos=None,
            dt_geneColor=dt_color,
        )
        plt.show()

        ad_metaEigengene = sc.AnnData(
            ad_meta.obsm["eigengene"], obs=ad_meta.obs, uns=ad_meta.uns
        )
        _dt = {x.split("ME")[-1]: [x] for x in ad_metaEigengene.var.index}
        axs = plotting.clustermap(
            ad_metaEigengene,
            _dt,
            obsAnno=ls_obs,
            layer=None,
            standard_scale=1,
            space_obsAnnoLegend=0.3,
            cbarPos=None,
            dt_geneColor=dt_color,
        )
        plt.show()

        ad_meta.varm["KME"] = ad_meta.varm["KME"].assign(
            kME=lambda df: df.apply(
                lambda x: x.at["kME" + x.at["Initially.Assigned.Module.Color"]], axis=1
            ),
            module=lambda df: df["Initially.Assigned.Module.Color"],
        )

        if calcAucell:
            getAUCellScore(
                ad,
                dt_moduleGene,
                layer,
                aucMaxRank=1000,
                label=f"{jobid}_AUCell",
                rEnv=renv,
            )
            if "X_umap" in ad.obsm:
                sc.pl.umap(
                    plotting.obsmToObs(ad, f"{jobid}_AUCell"),
                    color=ad.obsm[f"{jobid}_AUCell"].columns,
                    cmap="Reds",
                )
    # rlc.__exit__(None, None, None)
    ro.r.gc()
    return ad_meta


def useDiffxpyFindDegs(
        ad: sc.AnnData, obsKey: str, testName: str, backgroundName: Union[List[str], str, None] = None, layer:Union[None, str] = None,
        sizefactor:Union[None, str]=None, removeNotConv: bool = True, minCells=3, quickScale=True, category: Literal['both', 'up', 'down']='both',
    ) -> pd.DataFrame:
    import diffxpy.api as de
    if sizefactor is None:
        pass
    else:
        assert sizefactor in ad.obs.columns, f"sizefactor {sizefactor} not in ad.obs.columns"
    assert obsKey in ad.obs.columns, f"obsKey {obsKey} not in ad.obs.columns"
    if layer is None:
        pass
    else:
        assert layer in ad.layers.keys(), f"layer {layer} not in ad.layers.keys()"
    ls_allSamples = ad.obs[obsKey].unique().tolist()
    if isinstance(backgroundName, str):
        backgroundName = [backgroundName]
    elif backgroundName is None:
        backgroundName = [x for x in ls_allSamples if x != testName]
    
    _ls = [testName, *backgroundName]
    ad = ad[ad.obs.eval(f"{obsKey}.isin(@_ls)")].copy()
    if layer is None:
        ad = ad.copy()
    else:
        ad.X = ad.layers[layer].copy()
    del(ad.raw)
    sc.pp.filter_genes(ad, min_cells=minCells)
    ad.obs["diffxpy_temp"] = np.where(ad.obs[obsKey]==testName, 1, 0)
    ad.obs["diffxpy_temp"] = ad.obs["diffxpy_temp"].astype('category').cat.set_categories([0, 1])
    # if category == 'both':a
    #     pass
    # elif category == 'up': # reduce resource required
    #     ls_removeGene = adata.var.query("mean(adata.X[adata.obs.diffxpyUse=='b',:]) > mean(adata.X[adata.obs.diffxpyUse=='a',:])").index.to_list()
    #     adata = ad[:, ~ad.var.index.isin(ls_removeGene)].copy()
    # elif category == 'down':
    #     ls_removeGene = adata.var.query("mean(adata.X[adata.obs.diffxpyUse=='b',:]) < mean(adata.X[adata.obs.diffxpyUse=='a',:])").index.to_list()
    #     adata = adata[:, ~adata.var.index.isin(ls_removeGene)].copy()
    # else:
    #     raise ValueError(f"category {category} not supported")
    diffxpyTestResult = de.test.wald(
        ad,
        formula_loc="~1 + diffxpy_temp",
        coef_to_test=f"diffxpy_temp[T.1]",
        quick_scale=quickScale,
        size_factors=sizefactor,
        noise_model='nb'
    )
    df_diffxpyResult = diffxpyTestResult.summary()
    if removeNotConv:
        df_diffxpyResult = df_diffxpyResult.query("coef_sd > 2.222759e-162") # based on https://www.nature.com/articles/s41467-022-32229-9 and Delineating mouse β-cell identity during lifetime and in diabetes with a single cell atlas
    return df_diffxpyResult


def _mergeData(ad, obsKey, layer="raw"):
    basic.testAllCountIsInt(ad, layer)
    ls_keyProduct = ad.obs[obsKey].value_counts().sort_index().index.to_list()
    if isinstance(obsKey, str):
        ad.obs["temp_merge"] = ad.obs[obsKey].copy()
        obsKey = [obsKey]
    else:
        ad.obs["temp_merge"] = ad.obs[obsKey].apply(lambda x: tuple(x), axis=1)
    lsSr_onehot = []
    for col in ls_keyProduct:
        if isinstance(col, str):
            sr_col = (
                pd.Series(index=ad.obs.index, name="||".join([str(col)]))
                .fillna(0)
                .astype(int)
            )
        else:
            sr_col = (
                pd.Series(index=ad.obs.index, name="||".join([str(x) for x in col])).fillna(0).astype(int)
            )
        sr_col.where(ad.obs["temp_merge"] != col, 1, inplace=True)
        lsSr_onehot.append(sr_col)
    df_oneHot = pd.concat(lsSr_onehot, axis=1)
    ad_merge = sc.AnnData(
        df_oneHot.values.T @ ad.layers[layer],
        obs=pd.DataFrame(index=df_oneHot.columns),
        var=pd.DataFrame(index=ad.var.index),
    )
    ad_merge.obs = ad_merge.obs.index.to_series().str.split("\|\|", expand=True)
    ad_merge.obs.columns = obsKey
    del ad.obs["temp_merge"]
    return ad_merge


@rcontext
def timeSeriesAnalysisByMfuzz(
    ad,
    *,
    timeObs,
    clusterObs=None,
    filterGeneThres=0.8,
    geneClusterCounts=range(5, 75, 5),
    rFigsize=256,
    rcol=4,
    showNLargest=0,
    keyAdded="mfuzz",
    minMembership=0.3,
    palette="terrain_r",
    plotCounts=1000,
    repeats=3,
    threads=24,
    ls_useGenes=None,
    standardise=True,
    rEnv=None,
):
    """`timeSeriesAnalysisByMfuzz` is a function that takes in a single cell RNA-seq dataframe, performs
    time series analysis using the `mfuzz` R package

    Parameters
    ----------
    ad
        AnnData object
    timeObs
        the time points of the experiment
    filterGeneThres
        the threshold for filtering out genes with low expression.
    geneClusterCounts, optional
        number of gene clusters
    rFigsize
        the size of the figure to be generated by R
    rMfrow
        the number of rows and columns of plots to show in the R plot
    showNLargest, optional
        number of genes to show in the plot, if 0 plot all
    keyAdded, optional
        the key to be added to the adata object.
    rEnv
        R environment to use. If None, a new one will be created.

    """
    import rpy2
    import rpy2.robjects as ro
    from rpy2.robjects.packages import importr
    from math import ceil
    import pickle
    from . import plotting
    from ..rTools import (
        py2r,
        r2py,
        r_inline_plot,
        rHelp,
        trl,
        rGet,
        rSet,
        ad2so,
        so2ad,
        r_set_seed,
    )

    rBase = importr("base")
    rUtils = importr("utils")
    Mfuzz = importr("Mfuzz")
    importr("DescTools")
    R = ro.r
    r_set_seed(0)
    # print(1)
    def _calcClusterDistance(pkl_eset, pkl_m1, c, repeats):
        eset = pickle.loads(pkl_eset)
        m1 = pickle.loads(pkl_m1)
        ro.r("set.seed")(0)
        Mfuzz = importr("Mfuzz")
        result = Mfuzz.Dmin(eset, m=m1, crange=c, repeats=repeats, visu=False)[0]
        return c, result

    def _timeSeriesPlot(data, x, y, cmap="terrain_r", plotCounts=0, **kws):
        dt_membership = (
            data.loc[data["gene"].duplicated()]
            .set_index("gene")["membership"]
            .to_dict()
        )
        cmap = sns.palettes.color_palette(cmap, as_cmap=True)
        _df = data.pivot_table(y, index="gene", columns=x).reindex(
            sorted(dt_membership.keys(), key=lambda x: dt_membership[x])
        )
        if plotCounts > 0:
            _df = _df.iloc[-plotCounts:]
        for gene, ar_exp in _df.iterrows():
            plt.plot(range(len(ar_exp)), ar_exp, c=cmap(int(dt_membership[gene] * 255)))
        plt.xticks(range(len(ar_exp)), data[x].cat.categories)

    # assert (rMfrow[0] * rMfrow[1]) >= geneClusterCounts, "rMfrow[0] * rMfrow[1] < geneClusterCounts"

    if clusterObs is None:
        ad_merged = _mergeData(ad, timeObs)
        basic.initLayer(ad_merged, total=1e6)  # cpm
    else:
        dt_adMerged = {}
        for clusterName, ad_cluster in basic.splitAdata(
            ad, clusterObs, needName=True, copy=False
        ):
            _ad = _mergeData(ad_cluster, "Sample")
            _ad.var.index = _ad.var.index + "||" + clusterName
            basic.initLayer(_ad, total=1e6)  # cpm
            dt_adMerged[clusterName] = _ad
        ad_merged = sc.concat(dt_adMerged, axis=1)
    if ls_useGenes is None:
        ls_useGenes = ad_merged.var.index.to_list()

    ls_genePassFilter = (
        ((ad_merged.to_df("normalize_log") > 0).mean() >= filterGeneThres)
        .pipe(lambda sr: sr.loc[sr])
        .index.to_list()
    )
    # import pdb;pdb.set_trace()
    logger.info(f"{ad_merged.shape[1] - len(ls_genePassFilter)} genes excluded")
    ls_genePassFilter = list(set(ls_genePassFilter) & set(ls_useGenes))
    logger.info(f"Total used gene counts {len(ls_genePassFilter)}")

    if standardise:
        esR_Merged = R.ExpressionSet(
            rBase.as_matrix(py2r(ad_merged[:, ls_genePassFilter].to_df("normalize_log").T))
        )  # esR: ExpressionSet # mfuzz only recognized NA as missing value
    else:
        # zero center
        ad_merged.layers['center'] = ad_merged.layers['normalize_log'] - ad_merged.layers['normalize_log'].mean(0)
        esR_Merged = R.ExpressionSet(
            rBase.as_matrix(py2r(ad_merged[:, ls_genePassFilter].to_df("center").T))
        ) 


    rEnv["filterGeneThres"] = filterGeneThres
    rEnv["esR_Merged"] = esR_Merged
    rEnv["minMembership"] = minMembership
    rEnv["standardise"] = standardise

    R(
        """
    # esR_Merged.r <- filter.NA(esR_Merged, thres=filterGeneThres)
    # esR_Merged.f <- fill.NA(esR_Merged.r,mode=fillNaGeneMethod)
    if (standardise) {
        esR_Merged.s <- standardise(esR_Merged)
    } else {
        esR_Merged.s <- esR_Merged
    }
    m1 <- mestimate(esR_Merged.s)
    """
    )

    if isinstance(geneClusterCounts, int):
        pass
    else:
        ls_dminRes = Parallel(threads)(
            delayed(_calcClusterDistance)(
                pickle.dumps(rEnv["esR_Merged.s"]), pickle.dumps(rEnv["m1"]), x, repeats
            )
            for x in geneClusterCounts
        )
        plt.scatter(
            [x[0] for x in ls_dminRes], [x[1] for x in ls_dminRes], color="black", s=10
        )
        plt.show()
        # arR_crange = R.c(*geneClusterCounts)
        # dt_kwargsToDmin['crange'] = arR_crange
        # dt_kwargsToDmin['visu'] = True
        # dtR_kwargsToDmin = R.list(**dt_kwargsToDmin)
        # rEnv['dtR_kwargsToDmin'] = dtR_kwargsToDmin
        # with r_inline_plot():
        #     R("""
        #     dtR_kwargsToDmin$eset <- esR_Merged.s
        #     dtR_kwargsToDmin$m <- m1
        #     DoCall(Dmin, dtR_kwargsToDmin)
        #     """)

        geneClusterCounts = int(input())
    rrow = ceil(geneClusterCounts / rcol)
    rMfrow = (rrow, rcol)
    rEnv["geneClusterCounts"] = geneClusterCounts

    r_set_seed(0)
    R("cl <- mfuzz(esR_Merged.s, c=geneClusterCounts, m=m1)")

    vtR_sampleLabel = R.c(*ad.obs[timeObs].cat.categories)
    rEnv["vtR_sampleLabel"] = vtR_sampleLabel
    rEnv["rMfrow"] = R.c(*rMfrow)

    with r_inline_plot(rFigsize * rcol, rFigsize * rrow):
        R(
            "mfuzz.plot(esR_Merged.s,cl=cl,mfrow=rMfrow,new.window=FALSE, time.labels=vtR_sampleLabel)"
        )

    vtR_cluster = R("cl$cluster")
    df_ms = r2py(R("as.data.frame(cl$membership)"))
    dt_cluster = {x: y for x, y in zip(vtR_cluster.names, vtR_cluster)}
    df_ms = df_ms.assign(cluster=lambda df: df.index.map(dt_cluster).astype(str))
    df_ms = df_ms.assign(
        membership=lambda df: df.apply(lambda x: x.loc[x.loc["cluster"]], axis=1)
    )
    df_ms = df_ms.sort_values("cluster", key=lambda x: list(map(int, x)))
    sns.boxplot(data=df_ms.query("membership > 0.1"), x="cluster", y="membership")
    plt.show()

    df_mmPassed = (
        (
            df_ms.groupby("cluster")
            .apply(lambda df: df.nlargest(showNLargest, "membership"))
            .reset_index(level=0, drop=True)
        )
        if showNLargest > 0
        else df_ms
    )
    df_mmPassed = df_mmPassed.query("membership > @minMembership")
    df_MergedScaledMtx = r2py(rBase.as_data_frame(R.exprs(R("esR_Merged.s")))).T
    # _ad = ad_merged[:, df_mmPassed.index]
    # _ad.layers["normalize_log_scaled"] = _ad.layers["normalize_log"].copy()
    # sc.pp.scale(_ad, layer="normalize_log_scaled")

    _df = (
        df_MergedScaledMtx.melt(ignore_index=False, var_name="gene", value_name="exp")
        .rename_axis(timeObs)
        .reset_index()
        .merge(df_mmPassed[["cluster", "membership"]], left_on="gene", right_index=True)
        .sort_values("cluster", key=lambda x: list(map(int, x)))
    )

    _df[timeObs] = (
        _df[timeObs]
        .astype("category")
        .cat.set_categories(ad.obs[timeObs].cat.categories)
    )
    _df["cluster"] = (
        _df["cluster"]
        .astype("category")
        .cat.set_categories(sorted(_df["cluster"].unique(), key=int))
    )
    axs = sns.FacetGrid(
        _df,
        col="cluster",
        col_wrap=rMfrow[-1],
    )
    axs.map_dataframe(
        _timeSeriesPlot, x=timeObs, y="exp", cmap=palette, plotCounts=plotCounts
    )
    dt_geneCategoryCounts = (
        _df.groupby("cluster")["gene"].agg(lambda x: len(x.unique())).to_dict()
    )
    for ax, (category, geneCounts) in zip(
        axs.axes.flatten(), dt_geneCategoryCounts.items()
    ):
        plt.sca(ax)
        plt.title(f"Gene category {category}\n(N = {geneCounts})")
    # add colorbar
    ax_cbar = axs.fig.add_axes([1.015, 0.4, 0.015, 0.2])
    plt.sca(ax_cbar)
    cmap = mpl.cm.get_cmap(palette)
    norm = mpl.colors.Normalize(vmin=0, vmax=1)
    cb = mpl.colorbar.ColorbarBase(ax_cbar, cmap=cmap, norm=norm)
    cb.set_ticks([])
    plt.text(x=1, y=0.5, s="Membership value", ha="left", va="center", rotation=270)

    plt.tight_layout()
    plt.show()
    # axs = sns.FacetGrid(
    #     _df,
    #     col="cluster",
    #     col_wrap=rMfrow[-1],
    #     # hue="membership",
    #     # palette="viridis_r",
    #     #     hue_kws=dict(hue_norm=(0, 1)),
    # )
    # axs.map_dataframe(sns.lineplot, x=timeObs, y="exp", hue_norm=(0, 1), ci=None)
    # axs.set_titles(col_template="Gene category {col_name}")
    # plt.show()
    df_ms = df_ms.rename(columns={"cluster": "geneCategory"})
    ad_merged.varm[keyAdded] = df_ms.reindex(ad_merged.var.index)
    ad_merged.obsm[keyAdded] = df_MergedScaledMtx
    if clusterObs is None:
        ad.varm[keyAdded] = df_ms.reindex(ad.var.index)
    else:
        df_mfuzzMembership = (
            (
                df_ms.dropna().assign(
                    cellCluster=lambda df: df.index.str.split("\|\|").str[-1],
                    geneName=lambda df: df.index.str.split("\|\|").str[0],
                )
            )
            .set_index(["geneName", "cellCluster"])
            .unstack()
        )
        ad.varm[keyAdded] = df_mfuzzMembership.reindex(ad.var.index)

    return ad_merged


def getLigrecPairCounts(
    ad: sc.AnnData, ligrecKey: str, maxPValue: float, minMean: float
) -> pd.DataFrame:
    """It takes in an AnnData object, a ligrec key, a maximum p-value, and a minimum mean, and returns a
    dataframe of pairwise ligrec counts

    Parameters
    ----------
    ad : sc.Anndata
        the AnnData object
    ligrecKey : str
        the key of the ligrec results in the ad.uns
    maxPValue : float
        the maximum p-value for a ligand-receptor pair to be considered significant
    minMean : float
        the minimum mean expression of the ligand-receptor pair

    Returns
    -------
        A dataframe with the number of ligand-receptor pairs that have a p-value less than or equal to
    maxPValue and a mean greater than or equal to minMean.

    """
    df_pvalue = ad.uns[ligrecKey]["pvalues"]
    df_means = ad.uns[ligrecKey]["means"]
    ls_cluster = df_pvalue.columns.get_level_values(0).unique()

    from itertools import product

    dt_lrPairCounts = {}
    for sourceCluster, targetCluster in product(ls_cluster, ls_cluster):
        _df = pd.concat(
            (
                df_pvalue.xs((sourceCluster, targetCluster), axis=1).rename("p_value"),
                df_means.xs((sourceCluster, targetCluster), axis=1).rename("mean"),
            ),
            axis=1,
        ).query("p_value <= @maxPValue & mean >= @minMean")
        dt_lrPairCounts[(sourceCluster, targetCluster)] = len(_df)

    df_pairCounts = (
        pd.DataFrame(
            dt_lrPairCounts.values(),
            index=dt_lrPairCounts.keys(),
            columns=["pairCounts"],
        )
        .unstack()
        .droplevel(level=0, axis=1)
        .rename_axis(index="source", columns="target")
    )
    return df_pairCounts


def getGeneMeanAndExpressedRatio(ad:sc.AnnData, layer='raw', prefix=None) -> None:
    '''
    Parameters
    ----------
    ad : sc.AnnData
        the AnnData object
    layer, optional
        the layer of the AnnData object to use for the calculation
    prefix
        the prefix of the new columns. If None, the prefix will be 'mean' and 'expressedRatio'
    
    '''
    import scipy.sparse as ss
    if isinstance(ad.layers[layer], (ss.csr_matrix, ss.csc_matrix)):
        data = ss.csc_array(ad.layers[layer])
    else:
        data = ad.layers[layer]
    if prefix is None:
        prefix = ''
    ad.var[f'{prefix}mean'] = data.mean(axis=0)
    ad.var[f'{prefix}expressedRatio'] = (data > 0).mean(axis=0)
    ad.var[f'{prefix}expressedCount'] = (data > 0).sum(axis=0)


def getGeneMeanAndExpressedRatioGroups(ad:sc.AnnData, groupby:Union[str, List[str]], layer='raw'):
    '''It takes a single cell RNA-seq dataset, groups the cells by a categorical variable, and update the mean expression of each gene in each group, and the ratio of cells expressing
    each gene in each group
    
    Parameters
    ----------
    ad : sc.AnnData
        sc.AnnData: the AnnData object
    groupby : Union[str, List[str]]
        the column name in ad.obs that you want to group by.
    layer, optional
        the layer of the AnnData object to use for the analysis.
    
    '''
    if isinstance(groupby, str):
        groupby = [groupby]
    for group in groupby:
        for sample in ad.obs[group].unique():
            _ad = ad[ad.obs[group] == sample].copy()
            getGeneMeanAndExpressedRatio(_ad, layer=layer, prefix=f'{group}_{sample}_')
            ad.var.loc[_ad.var.index, f'{group}_{sample}_mean'] = _ad.var[f'{group}_{sample}_mean']
            ad.var.loc[_ad.var.index, f'{group}_{sample}_expressedRatio'] = _ad.var[f'{group}_{sample}_expressedRatio']
            ad.var.loc[_ad.var.index, f'{group}_{sample}_expressedCount'] = _ad.var[f'{group}_{sample}_expressedCount']
