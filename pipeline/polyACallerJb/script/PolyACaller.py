from collections import defaultdict
import os
import ont_fast5_api.fast5_interface
import pandas as pd
import numpy as np
import sys
import joblib
import datetime
import click
import multiprocessing

"""
wirte by Jia Jinbu 2020.09.12

Identify polyA region from raw nanopore signal.

see more by help.
"""

@click.command()
@click.option('-i', '--inadapter', help=('Input the file of adapter information of each read.'
                                         'Option format1: The file can be generated by bin/adapterFinder.py.'
                                         'In this case, the file contain read_core_id, polyA_type,'
                                         'r_align_start, f_align_end, genome_align_start, genome_align_end.'
                                         'Option format2: You also can provide one file directly contain column '
                                         'read_core_id, polyA_type, search_start_base, search_end_base'
                                         'polyA_type is A or T. If format is not format2, the script will '
                                         'convert them to format1. You also can directly provide file_fast5 column,'
                                         'In this case, you do not need set summary and fast5dir option'), 
                    required=True, type=click.Path(exists=True))
@click.option('-s', '--summary', help=('Input sequencing_summary.txt generated by basecalling software. '
                                       'If you do not provide, you must provide file_fast5 column in adapter file'), 
                    required=False, default="")          
@click.option('-f', '--fast5dir', help=('Input the directory of fast5 files. '
                                        'If you do not provide, you must provide file_fast5 column in adapter file'), 
                    required=False, default="")                              
@click.option('-o', '--out', help=("""Output File of polyA results.

                    \b
                    Output: Tab-seperated fromat
                    read_core_id        e909fc71-7798-4be9-81ea-11b8d5602005,chr1,1185559,1186502
                    polya_start_raw     1185
                    polya_end_raw       1924
                    polya_start_base    73
                    polya_end_base      77
                    polya_length        83.32693538067818
                    polya_score         740
                    polya_type          T
                    polya_start_raw, polya_end_raw: The raw signal event index of potential polyA region
                    polya_start_base, polya_end_base: The basecalled base position
                    polya_type: A or T
                    All is 1-based.
                    
                    """), required=True)
@click.option('-t', '--threads', required=False, default=10, help='Number of threads to use. (default: 10)')
def main(inadapter, summary, fast5dir, out, threads):
    """
    Identify polyA region from raw nanopore signal.
    
    \b
    require package:
    ont_fast5_api
    pandas
    numpy
    matplotlib #only if plot
    joblib
    
    """
    max_threads = multiprocessing.cpu_count()
    if threads > max_threads:
        max_threads = max_threads
    
    fast5_to_reads = read_adapter_info(inadapter, summary, fast5dir)
    
    #print(datetime.datetime.now())
    with joblib.Parallel(threads) as pool:    
            
        res = pool(
                joblib.delayed(extract_polya_from_reads)(file_fast5, adapter_data)
                for file_fast5, adapter_data in fast5_to_reads.groupby("file_fast5")
            )

        df = pd.concat(res)
        #df = df.drop(columns="polya_score")
        df.to_csv(out, sep="\t", index=False)
    #print(datetime.datetime.now())
  
def read_adapter_info(fileadapter, file_sequencing_summary=None, fast5_dir=None):
    
    """
    Input:
    fileadapter
    file_sequencing_summary (optional) generated by Guppy
    fast5_dir  (optional)
    
    Default read fileadapter as pandas dataframe.
    Require this column, but if not exist will be generated by other column except polyA_type:
    read_core_id, file_fast5, polyA_type, search_start_base, search_end_base
    
    read_id will be generated based on read_core_id.
    If not file_fast5, need file_sequencing_summary and fast5_dir
    If not search_start_base, search_end_base:
        require: r_align_start, f_align_end, genome_align_start, genome_align_end
    
    Output:
    A dataframe include read_core_id, read_id, file_fast5, polyA_type, search_start_base, search_end_base
    """
    
    def get_header(filein):
        """
        Return the header line (the first line) of one file.
        String format with "\n"
        """
        header = ""
        with open(filein) as f:
            header = next(f)
        return header

    def get_header_index(filein, select_column_names, sep="\t"):
        """
        Return the indexs (0-based) of select_column_names.
        If has duplicated column name, return the minmum index.
        
        Input:
        filein: has column name, tab-seperated
        select_column_names: column name list
        Return:
        a list, the indexs of select_column_names
        """
        select_indexs = []
        column_names = get_header(filein).rstrip("\n").split(sep)
        select_indexs = [column_names.index(column_name) for column_name in select_column_names]
        return select_indexs

    def read_by_column_names(filein, select_column_names, sep="\t"):
        select_indexs = get_header_index(filein, select_column_names, sep)
        with open(filein) as f:
            next(f)
            for l in f:
                d = l.rstrip("\n").split(sep)
                yield([d[i] for i in select_indexs]) 
            
    def read_sequencing_summary(filein, fast5_dir):
        read2file = {}
        for filename, read_id in read_by_column_names(filein, ["filename", "read_id"]):
            filename = os.path.join(fast5_dir, filename)
            read2file[read_id] = filename
        return read2file
        
    PAD_MAP_LENGTH = 10
    PAD_PRIMER_LENGTH = 5
    
    d = pd.read_table(fileadapter)
    if "read_id" not in d.columns:
        d["read_id"] = d["read_core_id"].map(lambda x: x.split(",")[0])
    if "file_fast5" not in d.columns:
        read2fast5file = read_sequencing_summary(file_sequencing_summary, fast5_dir)
        d["file_fast5"] = d["read_id"].map(read2fast5file)
    if ("search_start_base" not in d.columns) or ("search_end_base" not in d.columns):
        d["polyA_end"] = d["r_align_start"] - 1
        d["polyT_start"] = d["f_align_end"] + 1
        start_base = d["genome_align_end"] - PAD_MAP_LENGTH + 1
        end_base = d["r_align_start"] + PAD_PRIMER_LENGTH - 1
        tmp_flag = d["polyA_type"] == "T"
        start_base[tmp_flag] = d["f_align_end"][tmp_flag] - PAD_PRIMER_LENGTH  + 1
        end_base[tmp_flag] = d["genome_align_start"][tmp_flag] + PAD_MAP_LENGTH - 1
        start_base[start_base < 1] = 1
        #not used: will be checked in findpolyA method
        #tmp_flag = end_base > d["read_length"]
        #end_base[tmp_flag] = d["read_length"][tmp_flag]
        d["search_start_base"] = start_base
        d["search_end_base"] = end_base        
    return(d)

def max_subarray(A):
    """
    !!!The function in included in both polyCaller.py and 
    pacbio_find_polyA.py. They are same function, but haven't
    be put in a module to keep each script can be run independently.
    If you want to modify one of them, please modify them at the 
    same time. 

    Maximum subarray problem: select subarray with maxmium sum
    modified Kadane's algorithm (not greedy)
    
    return (index is 0-based), you can get the subarray by A[start_index:(end_index+1)]:
    [start_index, end_index, sum]
    
    if the maxmium sum is <= 0, then return [-1, -1, 0]
    """
        
    max_ending_here = max_so_far = 0
    max_start_index = startIndex = 0
    max_end_index = -1
    for i, x in enumerate(A):
        if 0 >= max_ending_here + x:
        #For greedy at left side : if 0 > max_ending_here + x:
            startIndex = i+1
            max_ending_here = 0
        else:
            max_ending_here += x
        if max_ending_here > max_so_far:
        #For greedy at right side : if max_ending_here >= max_so_far:
            max_so_far = max_ending_here
            max_start_index = startIndex
            max_end_index = i
    
    if max_so_far <= 0 or (max_start_index > max_end_index):
        return ((-1, -1, 0))
    else:
        return (max_start_index, max_end_index, max_so_far)
    
def polyA_finder(seq, base="A", match = 1, mis = -1.5):
    """
    !!!The function in included in both polyCaller.py and 
    pacbio_find_polyA.py. They are same function, but haven't
    be put in a module to keep each script can be run independently.
    If you want to modify one of them, please modify them at the 
    same time.
    """
    scores = [match if base == s else mis for s in seq]
    start_index, end_index, max_score = max_subarray(scores)
    return (start_index+1, end_index+1, max_score, seq[start_index:(end_index+1)])

def extract_polya_from_reads(file_fast5, adapter_data):
    #require import ont_fast5_api.fast5_interface   import pandas as pd
    results = []
    read_core_ids = []
    with ont_fast5_api.fast5_interface.get_fast5_file(file_fast5, mode="r") as IN:
        for na, row in adapter_data.iterrows():
            read_core_id = row["read_core_id"]
            read_id = row["read_id"]
            read = Fast5Read(IN, read_id)
            result = read.find_polyA(row["polyA_type"], 
                               row["search_start_base"], 
                               row["search_end_base"])
            read_core_ids.append(read_core_id)
            results.append(result)
    results = pd.DataFrame(results, columns=["polya_start_raw", "polya_end_raw", 
                            "polya_start_base", "polya_end_base", "polya_length", 
                            "polya_score", "polya_type"])
    results["read_core_id"] = read_core_ids
    #move read_core_id to the first column
    results = results[["read_core_id", "polya_start_raw", "polya_end_raw", 
                            "polya_start_base", "polya_end_base", "polya_length", 
                            "polya_score", "polya_type"]]
    return results
        
class Fast5Read():
    
    """
    require package: import numpy as np \n import pandas as pd
    require function: max_subarray
    
    Note: After fast5 IO is closed, the read object generated from fast5 IO didn't work (return None).
        
    """
    
    def __init__(self, IN, read_id=None, basecall_group=None):
        self.read(IN, read_id)
        
    def read(self, IN, read_id=None, basecall_group=None):
        
        """
        read.get_analysis_attributes(basecall_group) is a dict:
        {'component': 'basecall_1d',
         'model_type': 'flipflop',
         'name': 'ONT Guppy basecalling software.',
         'segmentation': 'Segmentation_000',
         'time_stamp': '2020-03-10T09:56:33Z',
         'version': '3.3.0+ef22818'}
         
        read.get_summary_data(segmentation_name) 
        {'segmentation': {'adapter_max': 0.0,
         'duration_template': 6465,
         'first_sample_template': 766,
         'has_complement': 0,
         'has_template': 1,
         'med_abs_dev_template': 8.23161506652832,
         'median_template': 86.69466400146484,
         'num_events_template': 3232,
         'pt_detect_success': 0,
         'pt_median': 0.0,
        'pt_sd': 0.0}}

        event_table
        ------------------------------------
        |start|base_index|base|event_length|
        |766  |     1    |  G | 12         |
        |778  |     2    |  C | 2          |
        ------------------------------------
        """
        
        if not read_id:
            read_id = IN.get_read_ids()[0]
        read = IN.get_read(read_id)
        if not basecall_group:
            basecall_group = read.get_latest_analysis("Basecall_1D")
        
        self.read_id = read_id
        self.read = read
        self.io = IN
        self.basecall_group = basecall_group
        
        template_name = basecall_group + "/BaseCalled_template" 
        self.basecall_group_attributes = read.get_analysis_attributes(basecall_group)
        segmentation_name = self.basecall_group_attributes['segmentation']
        if self.basecall_group_attributes['model_type'] != 'flipflop':
            raise ValueError('model type is not flipflop')
        self.raw_data = read.get_raw_data()
        #raw_data: array([805, 496, 514, ..., 521, 531, 643], dtype=int16)
        self.basecall_summary = read.get_summary_data(basecall_group)['basecall_1d_template']
        self.stride = stride = self.basecall_summary['block_stride']
        self.fastq = read.get_analysis_dataset(group_name=template_name, dataset_name='Fastq')
        self.seq = self.fastq.split("\n")[1]
        self.segmentation_summary = read.get_summary_data(segmentation_name)['segmentation']
        self.start = start = self.segmentation_summary['first_sample_template']
        self.move = move = read.get_analysis_dataset(group_name=template_name, dataset_name='Move')
        #move: array([1, 0, 0, ..., 0, 0, 0], dtype=uint8)
        self.event_length = event_length = len(self.move)
        self.end = end = start + (event_length - 1) * stride            
        
        #generate event table
        ls_move_raw_start = (np.arange(event_length)[move==1])*stride + start
        ls_move_raw_start_with_end = np.append(ls_move_raw_start, end)
        ls_event_length = ls_move_raw_start_with_end[1:] - ls_move_raw_start
        self.event_table = pd.DataFrame({"start": ls_move_raw_start, 
                                    "base": list(self.seq), 
                                    "event_length": ls_event_length})
        self.samples_per_nt = np.mean(ls_event_length[ls_event_length <=np.quantile(ls_event_length, 0.95)])
        
    def find_polyA(self, find_base="A", start_base=None, end_base=None, 
                   min_polya_length=15, match_score=1, mismatch_score=-1.5,
                   long_event_base_ratio=20):
        #not greedy
        
        #if not provide start_base and end_base, search total read
        if not start_base:
            start_base = 1
        seq_length = len(self.event_table.index)
        if not end_base or end_base > seq_length:
            end_base = seq_length
        #if not provide find_base, try find A and find T, 
        #then return the best result
        if not find_base:
            polya_result = self.find_polyA("A", start_base, end_base, 
                                min_polya_length, match_score, mismatch_score, 
                                long_event_base_ratio)
            polyt_result = self.find_polyA("T", start_base, end_base, 
                                min_polya_length, match_score, mismatch_score, 
                                long_event_base_ratio)
            result = polya_result if polya_result[-3] >= polyt_result[-3] else polyt_result
            (self.polya_start, self.polya_end, self.polya_start_base, 
                 self.polya_end_base, self.polya_length, self.polya_score,
                 self.polya_type) = result
            return result
        #start_base bigger than end_base, wrong
        if start_base > end_base:
            (self.polya_start, self.polya_end, self.polya_start_base, 
                 self.polya_end_base, self.polya_length, self.polya_score,
                 self.polya_type) = result = (0, 0, 0, 0, 0, 0, find_base)
            return result
        
        e = self.event_table.iloc[(start_base-1):end_base, :]
        samples_per_nt = self.samples_per_nt
        
        base_is_right = e.base.values == find_base
        
        #convert long event base near A to A
        near_A = np.logical_or(np.insert(base_is_right[:-1], 0, False),
                      np.append(base_is_right[1:], False))
        base_is_right[np.logical_and(e.event_length.values >= samples_per_nt * long_event_base_ratio,
                       near_A)] = True
        
        #call polya
        scores = np.where(base_is_right, match_score, mismatch_score) \
                    * e.event_length.values
        start_index, end_index, max_score = max_subarray(scores)
        
        #calculate polya position
        if start_index != -1: # -1 indicate not find polyA
            self.polya_start = e.start.values[start_index]
            self.polya_end = e.start.values[end_index] + e.event_length.values[end_index]
            self.polya_start_base = start_base + start_index
            self.polya_end_base = start_base + end_index
            self.polya_length = round((self.polya_end - self.polya_start)/samples_per_nt, 2)
        else:
            self.polya_start = 0
            self.polya_end = 0
            self.polya_start_base = 0
            self.polya_end_base = 0
            self.polya_length  = 0
        self.polya_score = max_score
        self.polya_type = find_base
        
        return([self.polya_start, self.polya_end, self.polya_start_base, 
             self.polya_end_base, self.polya_length, self.polya_score,
             self.polya_type])

    def plot(self, figsize = None, plot_base=False, plot_base_line=False, xlim=None, ylim=None):
        import matplotlib.pyplot as plt
        raw_data = self.raw_data
        event_table = self.event_table #don't change
        end = self.end
        start = self.start
        
        plot_polya = True
        try:
            polya_start = self.polya_start
            polya_end = self.polya_end
            polya_type = self.polya_type
            polya_length = self.polya_length
        except:
            plot_polya = False

        if figsize:
            fig, ax = plt.subplots(figsize=figszie)
        else:
            fig, ax = plt.subplots()
            
        ax.plot(np.arange(len(raw_data)), raw_data)
        ax.axvspan(start, end, facecolor='g', alpha=0.25)
        ax.axvspan(polya_start, polya_end, facecolor='r', alpha=0.25)                    

        if plot_base:
            starts = event_table["start"]
            ends = np.append(event_table["start"][1:], end)
            bases = event_table["base"]
            for start, end, base in zip(starts, ends, bases):
                y_pos = raw_data[start:end].max() + 10
                ax.text((start+end-1)/2, y_pos, base, clip_on=True, horizontalalignment="center",
                       verticalalignment='center') #base + str(end-start)
                if plot_base_line:
                    ax.axvline(start, color="grey", zorder=1)
            if plot_base_line:
                    ax.axvline(end, color="grey", zorder=1)
        
        if xlim:
            ax.set_xlim(xlim)
        if ylim:
            ax.set_ylim(ylim)
            
        self.ax = ax
        self.fig = fig
        
    def savefig(self, filename):
        self.fig.savefig(filename)
    
if __name__ == '__main__':
    main()
    