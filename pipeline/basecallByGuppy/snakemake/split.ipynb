{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:26:42.671926Z",
     "iopub.status.busy": "2021-09-27T07:26:42.671527Z",
     "iopub.status.idle": "2021-09-27T07:26:42.675479Z",
     "shell.execute_reply": "2021-09-27T07:26:42.674720Z",
     "shell.execute_reply.started": "2021-09-27T07:26:42.671892Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jpy_tools.parseSnake2 as jps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:26:42.677153Z",
     "iopub.status.busy": "2021-09-27T07:26:42.676668Z",
     "iopub.status.idle": "2021-09-27T07:26:42.680375Z",
     "shell.execute_reply": "2021-09-27T07:26:42.679706Z",
     "shell.execute_reply.started": "2021-09-27T07:26:42.677126Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_config = \"/public/home/liuzj/scripts/pipeline/basecallByGuppy/snakemake/config.yaml\"\n",
    "path_sf = \"/public/home/liuzj/scripts/pipeline/basecallByGuppy/snakemake/snakefile\"\n",
    "dir_scripts = \"/scem/work/liuzj/github/Liuzj_allScripts/pipeline/basecallByGuppy/scripts/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:26:42.682165Z",
     "iopub.status.busy": "2021-09-27T07:26:42.681887Z",
     "iopub.status.idle": "2021-09-27T07:26:42.685025Z",
     "shell.execute_reply": "2021-09-27T07:26:42.684392Z",
     "shell.execute_reply.started": "2021-09-27T07:26:42.682140Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sf = jps.SnakeFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:26:42.686537Z",
     "iopub.status.busy": "2021-09-27T07:26:42.686266Z",
     "iopub.status.idle": "2021-09-27T07:26:42.694076Z",
     "shell.execute_reply": "2021-09-27T07:26:42.693459Z",
     "shell.execute_reply.started": "2021-09-27T07:26:42.686512Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import pandas as pd\n",
       "#configfile: \"/public/home/liuzj/scripts/pipeline/basecallByGuppy/snakemake/config.yaml\"\n",
       "pipelineDir = config['pipelineDir']\n",
       "resultDir = config[\"resultDir\"].rstrip(\"/\") + \"/\"\n",
       "pipelineDir = config[\"pipelineDir\"].rstrip(\"/\") + \"/\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = jps.SnakeHeader(sf, path_config)\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:26:42.695295Z",
     "iopub.status.busy": "2021-09-27T07:26:42.695026Z",
     "iopub.status.idle": "2021-09-27T07:26:42.698839Z",
     "shell.execute_reply": "2021-09-27T07:26:42.698235Z",
     "shell.execute_reply.started": "2021-09-27T07:26:42.695271Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = header.getConfig()\n",
    "resultDir = config[\"resultDir\"].rstrip(\"/\") + \"/\"\n",
    "pipelineDir = config[\"pipelineDir\"].rstrip(\"/\") + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:26:42.700204Z",
     "iopub.status.busy": "2021-09-27T07:26:42.699936Z",
     "iopub.status.idle": "2021-09-27T07:26:42.704715Z",
     "shell.execute_reply": "2021-09-27T07:26:42.703996Z",
     "shell.execute_reply.started": "2021-09-27T07:26:42.700178Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipelineDir': '/scem/work/liuzj/github/Liuzj_allScripts/pipeline/basecallByGuppy/scripts/',\n",
       " 'resultDir': '/scem/work/liuzj/projects/mouse/basecalledFastq/',\n",
       " 'guppy': '~/softwares/ont-guppy-4.2/bin/guppy_basecaller',\n",
       " 'model': '~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg',\n",
       " 'input': {'all': {'path': '/scem/work/liuzj/projects/mouse/allFast5/20210723_1345_MN29338_FAQ41752_7386409e/fast5/',\n",
       "   'nparts': 12,\n",
       "   'need_h5': False}}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:26:42.706724Z",
     "iopub.status.busy": "2021-09-27T07:26:42.706443Z",
     "iopub.status.idle": "2021-09-27T07:26:42.713482Z",
     "shell.execute_reply": "2021-09-27T07:26:42.712858Z",
     "shell.execute_reply.started": "2021-09-27T07:26:42.706699Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dt_h5 = config['input']\n",
    "df_splitH5 = pd.DataFrame.from_dict(dt_h5).T\n",
    "df_splitH5['dir_output'] = df_splitH5.index + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:26:42.715026Z",
     "iopub.status.busy": "2021-09-27T07:26:42.714753Z",
     "iopub.status.idle": "2021-09-27T07:26:42.723876Z",
     "shell.execute_reply": "2021-09-27T07:26:42.723257Z",
     "shell.execute_reply.started": "2021-09-27T07:26:42.715001Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 15:26:42.717 | INFO     | jpy_tools.parseSnake2:addRule:55 - splitH5 step num: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "## get parameter of rule `splitH5` ##\n",
       "import pandas as pd\n",
       "dt_h5 = config['input']\n",
       "df_splitH5 = pd.DataFrame.from_dict(dt_h5).T\n",
       "df_splitH5['dir_output'] = df_splitH5.index + '/'\n",
       "for column in ['dir_output']:\n",
       "    df_splitH5[column] = resultDir + 'step1_splitH5/' + df_splitH5[column]\n",
       "----------------\n",
       "IN RULE\n",
       "----------------\n",
       "# parameter's dataframe of splitH5: \n",
       "# |     | need_h5   |   nparts | path                                                                                    | dir_output   |\n",
       "# |:----|:----------|---------:|:----------------------------------------------------------------------------------------|:-------------|\n",
       "# | all | False     |       12 | /scem/work/liuzj/projects/mouse/allFast5/20210723_1345_MN29338_FAQ41752_7386409e/fast5/ | all/         |\n",
       "rule splitH5:\n",
       "    input:\n",
       "        path = lambda wildcard: df_splitH5.at[wildcard.sample, 'path'],\n",
       "    output:\n",
       "        splitH5Finished = resultDir + 'step1_splitH5/' + '{sample}.finished',\n",
       "    params:\n",
       "        gpu = 0,\n",
       "        nparts = lambda wildcard: df_splitH5.at[wildcard.sample, 'nparts'],\n",
       "        dir_output = lambda wildcard: df_splitH5.at[wildcard.sample, 'dir_output'],\n",
       "    threads:1\n",
       "    priority:0\n",
       "    shell:\n",
       "        \"\"\"\n",
       "cd {pipelineDir}\n",
       "python ./splitFast5ToMultipleDir.py -i {input.path} -o {params.dir_output} -n {params.nparts}\n",
       "touch {output.splitH5Finished}\n",
       "        \"\"\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_splitH5 = jps.SnakeRule(sf, 'splitH5', 1)\n",
    "rule_splitH5.addCode(\"\"\"\n",
    "import pandas as pd\n",
    "dt_h5 = config['input']\n",
    "df_splitH5 = pd.DataFrame.from_dict(dt_h5).T\n",
    "df_splitH5['dir_output'] = df_splitH5.index + '/'\n",
    "\"\"\")\n",
    "rule_splitH5.addMetaDf('df_splitH5', ['dir_output'], df_splitH5)\n",
    "rule_splitH5.addMain('input', ['path'])\n",
    "rule_splitH5.addMain('params', ['nparts', 'dir_output'])\n",
    "rule_splitH5.setShell(\"\"\"\n",
    "cd {pipelineDir}\n",
    "python ./splitFast5ToMultipleDir.py -i {input.path} -o {params.dir_output} -n {params.nparts}\n",
    "\"\"\")\n",
    "rule_splitH5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:26:42.725096Z",
     "iopub.status.busy": "2021-09-27T07:26:42.724826Z",
     "iopub.status.idle": "2021-09-27T07:26:42.741160Z",
     "shell.execute_reply": "2021-09-27T07:26:42.740521Z",
     "shell.execute_reply.started": "2021-09-27T07:26:42.725071Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_basecall = df_splitH5.copy()\n",
    "df_basecall[\"nparts\"] = df_basecall[\"nparts\"].map(lambda x: list(range(x)))\n",
    "df_basecall = df_basecall.explode(\"nparts\")\n",
    "df_basecall = df_basecall[[\"nparts\", \"dir_output\"]]\n",
    "df_basecall['sample'] = df_basecall.index\n",
    "df_basecall.index = df_basecall.index + \"_\" + df_basecall.nparts.astype(str)\n",
    "df_basecall.dir_output = df_basecall.dir_output + df_basecall.nparts.astype(str) + '/'\n",
    "df_basecall['basecalledDir'] = df_basecall.index + '/'\n",
    "df_basecall['guppy'] = config['guppy']\n",
    "df_basecall['model'] = config['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:26:42.742442Z",
     "iopub.status.busy": "2021-09-27T07:26:42.742095Z",
     "iopub.status.idle": "2021-09-27T07:26:42.756556Z",
     "shell.execute_reply": "2021-09-27T07:26:42.755944Z",
     "shell.execute_reply.started": "2021-09-27T07:26:42.742417Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 15:26:42.745 | INFO     | jpy_tools.parseSnake2:addRule:55 - basecall step num: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "## get parameter of rule `basecall` ##\n",
       "df_basecall = df_splitH5.copy()\n",
       "df_basecall[\"nparts\"] = df_basecall[\"nparts\"].map(lambda x: list(range(x)))\n",
       "df_basecall = df_basecall.explode(\"nparts\")\n",
       "df_basecall = df_basecall[[\"nparts\", \"dir_output\"]]\n",
       "df_basecall['sample'] = df_basecall.index\n",
       "df_basecall.index = df_basecall.index + \"_\" + df_basecall.nparts.astype(str)\n",
       "df_basecall.dir_output = df_basecall.dir_output + df_basecall.nparts.astype(str) + '/'\n",
       "df_basecall['basecalledDir'] = df_basecall.index + '/'\n",
       "df_basecall['guppy'] = config['guppy']\n",
       "df_basecall['model'] = config['model']\n",
       "for column in ['basecalledDir']:\n",
       "    df_basecall[column] = resultDir + 'step2_basecall/' + df_basecall[column]\n",
       "\n",
       "def parseDfToInput_basecall_splitH5(wildcard):\n",
       "    selfWildCardUnique = True\n",
       "    if isinstance(df_basecall.at[wildcard.sampleSplit, 'sample'], list):\n",
       "        selfWildCardUnique = False\n",
       "    if selfWildCardUnique:\n",
       "        return resultDir + 'step1_splitH5/' + df_basecall.at[wildcard.sampleSplit, 'sample'] + '.finished'\n",
       "    else:\n",
       "        return [resultDir + 'step1_splitH5/' + x + '.finished' for x in df_basecall.loc[wildcard.sampleSplit, 'sample']]\n",
       "\n",
       "def parseDfToParams_basecall_splitH5_need_h5(wildcard):\n",
       "    selfWildCardUnique = True\n",
       "    if isinstance(df_basecall.at[wildcard.sampleSplit, 'sample'], list):\n",
       "        selfWildCardUnique = False\n",
       "    if selfWildCardUnique:\n",
       "        fromSampleName = df_basecall.at[wildcard.sampleSplit, 'sample']\n",
       "        return df_splitH5.at[fromSampleName, 'need_h5']\n",
       "    else:\n",
       "        ls_fromSampleName = df_basecall.loc[wildcard.sampleSplit, 'sample']\n",
       "        return [df_splitH5.at[x, 'need_h5'] for x in ls_fromSampleName]\n",
       "----------------\n",
       "IN RULE\n",
       "----------------\n",
       "# parameter's dataframe of basecall: \n",
       "# |        |   nparts | dir_output   | sample   | basecalledDir   | guppy                                          | model                                                    |\n",
       "# |:-------|---------:|:-------------|:---------|:----------------|:-----------------------------------------------|:---------------------------------------------------------|\n",
       "# | all_0  |        0 | all/0/       | all      | all_0/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all_1  |        1 | all/1/       | all      | all_1/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all_2  |        2 | all/2/       | all      | all_2/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all_3  |        3 | all/3/       | all      | all_3/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all_4  |        4 | all/4/       | all      | all_4/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all_5  |        5 | all/5/       | all      | all_5/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all_6  |        6 | all/6/       | all      | all_6/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all_7  |        7 | all/7/       | all      | all_7/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all_8  |        8 | all/8/       | all      | all_8/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all_9  |        9 | all/9/       | all      | all_9/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all_10 |       10 | all/10/      | all      | all_10/         | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all_11 |       11 | all/11/      | all      | all_11/         | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "rule basecall:\n",
       "    input:\n",
       "        splitH5Finished = parseDfToInput_basecall_splitH5,\n",
       "    output:\n",
       "        basecallFinished = resultDir + 'step2_basecall/' + '{sampleSplit}.finished',\n",
       "    params:\n",
       "        gpu = 2,\n",
       "        need_h5 = parseDfToParams_basecall_splitH5_need_h5,\n",
       "        dir_output = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'dir_output'],\n",
       "        basecalledDir = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'basecalledDir'],\n",
       "        guppy = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'guppy'],\n",
       "        model = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'model'],\n",
       "    threads:18\n",
       "    priority:0\n",
       "    shell:\n",
       "        \"\"\"\n",
       "if [ {params.need_h5} = True ]\n",
       "then\n",
       "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings --fast5_out\n",
       "else\n",
       "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings\n",
       "fi\n",
       "touch {output.basecallFinished}\n",
       "        \"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_basecall = jps.SnakeRule(sf, \"basecall\", 18, 2, wildCard=\"sampleSplit\")\n",
    "rule_basecall.addCode(\n",
    "    \"\"\"\n",
    "df_basecall = df_splitH5.copy()\n",
    "df_basecall[\"nparts\"] = df_basecall[\"nparts\"].map(lambda x: list(range(x)))\n",
    "df_basecall = df_basecall.explode(\"nparts\")\n",
    "df_basecall = df_basecall[[\"nparts\", \"dir_output\"]]\n",
    "df_basecall['sample'] = df_basecall.index\n",
    "df_basecall.index = df_basecall.index + \"_\" + df_basecall.nparts.astype(str)\n",
    "df_basecall.dir_output = df_basecall.dir_output + df_basecall.nparts.astype(str) + '/'\n",
    "df_basecall['basecalledDir'] = df_basecall.index + '/'\n",
    "df_basecall['guppy'] = config['guppy']\n",
    "df_basecall['model'] = config['model']\n",
    "\"\"\"\n",
    ")\n",
    "rule_basecall.addMetaDf(\"df_basecall\", [\"basecalledDir\"], metaDf = df_basecall)\n",
    "rule_basecall.addMain(\"params\", [\"need_h5\"], rule_splitH5)\n",
    "rule_basecall.addMain(\"params\", [\"dir_output\", \"basecalledDir\", \"guppy\", \"model\"])\n",
    "\n",
    "rule_basecall.setShell(\"\"\"\n",
    "if [ {params.need_h5} = True ]\n",
    "then\n",
    "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings --fast5_out\n",
    "else\n",
    "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings\n",
    "fi\n",
    "\"\"\")\n",
    "rule_basecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:26:42.757770Z",
     "iopub.status.busy": "2021-09-27T07:26:42.757494Z",
     "iopub.status.idle": "2021-09-27T07:26:42.766971Z",
     "shell.execute_reply": "2021-09-27T07:26:42.766150Z",
     "shell.execute_reply.started": "2021-09-27T07:26:42.757745Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mergeFq = df_basecall.reset_index().groupby(\"sample\")[\"index\"].agg(list).pipe(\n",
    "    pd.DataFrame\n",
    ").rename(columns={\"index\": \"sampleSplit\"}).assign(dir_out=lambda df: df.index + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:26:42.768325Z",
     "iopub.status.busy": "2021-09-27T07:26:42.768015Z",
     "iopub.status.idle": "2021-09-27T07:26:42.778326Z",
     "shell.execute_reply": "2021-09-27T07:26:42.777651Z",
     "shell.execute_reply.started": "2021-09-27T07:26:42.768296Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 15:26:42.771 | INFO     | jpy_tools.parseSnake2:addRule:55 - mergeFq step num: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "## get parameter of rule `mergeFq` ##\n",
       "df_mergeFq = df_basecall.reset_index().groupby(\"sample\")[\"index\"].agg(list).pipe(\n",
       "    pd.DataFrame\n",
       ").rename(columns={\"index\": \"sampleSplit\"}).assign(dir_out=lambda df: df.index + \"/\")\n",
       "for column in ['dir_out']:\n",
       "    df_mergeFq[column] = resultDir + 'step3_mergeFq/' + df_mergeFq[column]\n",
       "\n",
       "def parseDfToInput_mergeFq_basecall(wildcard):\n",
       "    selfWildCardUnique = True\n",
       "    if isinstance(df_mergeFq.at[wildcard.sample, 'sampleSplit'], list):\n",
       "        selfWildCardUnique = False\n",
       "    if selfWildCardUnique:\n",
       "        return resultDir + 'step2_basecall/' + df_mergeFq.at[wildcard.sample, 'sampleSplit'] + '.finished'\n",
       "    else:\n",
       "        return [resultDir + 'step2_basecall/' + x + '.finished' for x in df_mergeFq.loc[wildcard.sample, 'sampleSplit']]\n",
       "\n",
       "def parseDfToParams_mergeFq_basecall_basecalledDir(wildcard):\n",
       "    selfWildCardUnique = True\n",
       "    if isinstance(df_mergeFq.at[wildcard.sample, 'sampleSplit'], list):\n",
       "        selfWildCardUnique = False\n",
       "    if selfWildCardUnique:\n",
       "        fromSampleName = df_mergeFq.at[wildcard.sample, 'sampleSplit']\n",
       "        return df_basecall.at[fromSampleName, 'basecalledDir']\n",
       "    else:\n",
       "        ls_fromSampleName = df_mergeFq.loc[wildcard.sample, 'sampleSplit']\n",
       "        return [df_basecall.at[x, 'basecalledDir'] for x in ls_fromSampleName]\n",
       "----------------\n",
       "IN RULE\n",
       "----------------\n",
       "# parameter's dataframe of mergeFq: \n",
       "# | sample   | sampleSplit                                                                                                    | dir_out   |\n",
       "# |:---------|:---------------------------------------------------------------------------------------------------------------|:----------|\n",
       "# | all      | ['all_0', 'all_1', 'all_2', 'all_3', 'all_4', 'all_5', 'all_6', 'all_7', 'all_8', 'all_9', 'all_10', 'all_11'] | all/      |\n",
       "rule mergeFq:\n",
       "    input:\n",
       "        basecallFinished = parseDfToInput_mergeFq_basecall,\n",
       "    output:\n",
       "        mergeFqFinished = resultDir + 'step3_mergeFq/' + '{sample}.finished',\n",
       "    params:\n",
       "        gpu = 0,\n",
       "        basecalledDir = parseDfToParams_mergeFq_basecall_basecalledDir,\n",
       "        dir_out = lambda wildcard: df_mergeFq.at[wildcard.sample, 'dir_out'],\n",
       "    threads:18\n",
       "    priority:0\n",
       "    shell:\n",
       "        \"\"\"\n",
       "mkdir -p {params.dir_out}\n",
       "cd {pipelineDir}\n",
       "python mergeFastq.py {params.basecalledDir} -o {params.dir_out} -t {threads}\n",
       "touch {output.mergeFqFinished}\n",
       "        \"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_mergeFq = jps.SnakeRule(sf, 'mergeFq', 18, 0)\n",
    "rule_mergeFq.addCode(\"\"\"\n",
    "df_mergeFq = df_basecall.reset_index().groupby(\"sample\")[\"index\"].agg(list).pipe(\n",
    "    pd.DataFrame\n",
    ").rename(columns={\"index\": \"sampleSplit\"}).assign(dir_out=lambda df: df.index + \"/\")\n",
    "\"\"\")\n",
    "rule_mergeFq.addMetaDf('df_mergeFq', ['dir_out'], metaDf=df_mergeFq)\n",
    "rule_mergeFq.addMain('params', ['basecalledDir'], fromRule=rule_basecall)\n",
    "rule_mergeFq.addMain('params', ['dir_out'])\n",
    "rule_mergeFq.setShell(\"\"\"\n",
    "mkdir -p {params.dir_out}\n",
    "cd {pipelineDir}\n",
    "python mergeFastq.py {params.basecalledDir} -o {params.dir_out} -t {threads}\n",
    "\"\"\")\n",
    "rule_mergeFq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:26:42.779652Z",
     "iopub.status.busy": "2021-09-27T07:26:42.779350Z",
     "iopub.status.idle": "2021-09-27T07:26:42.784079Z",
     "shell.execute_reply": "2021-09-27T07:26:42.783346Z",
     "shell.execute_reply.started": "2021-09-27T07:26:42.779612Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rule all:\n",
       "    input:\n",
       "        mergeFqFinished = [resultDir + 'step3_mergeFq/' + \"\" + sample + \".finished\" for sample in df_mergeFq.index],"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_all = jps.SnakeAll(sf, rule_mergeFq)\n",
    "rule_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:26:42.785273Z",
     "iopub.status.busy": "2021-09-27T07:26:42.785003Z",
     "iopub.status.idle": "2021-09-27T07:26:42.789340Z",
     "shell.execute_reply": "2021-09-27T07:26:42.788586Z",
     "shell.execute_reply.started": "2021-09-27T07:26:42.785248Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "#configfile: \"/public/home/liuzj/scripts/pipeline/basecallByGuppy/snakemake/config.yaml\"\n",
      "pipelineDir = config['pipelineDir']\n",
      "resultDir = config[\"resultDir\"].rstrip(\"/\") + \"/\"\n",
      "pipelineDir = config[\"pipelineDir\"].rstrip(\"/\") + \"/\"\n",
      "\n",
      "\n",
      "## get parameter of rule `splitH5` ##\n",
      "import pandas as pd\n",
      "dt_h5 = config['input']\n",
      "df_splitH5 = pd.DataFrame.from_dict(dt_h5).T\n",
      "df_splitH5['dir_output'] = df_splitH5.index + '/'\n",
      "for column in ['dir_output']:\n",
      "    df_splitH5[column] = resultDir + 'step1_splitH5/' + df_splitH5[column]\n",
      "\n",
      "\n",
      "## get parameter of rule `basecall` ##\n",
      "df_basecall = df_splitH5.copy()\n",
      "df_basecall[\"nparts\"] = df_basecall[\"nparts\"].map(lambda x: list(range(x)))\n",
      "df_basecall = df_basecall.explode(\"nparts\")\n",
      "df_basecall = df_basecall[[\"nparts\", \"dir_output\"]]\n",
      "df_basecall['sample'] = df_basecall.index\n",
      "df_basecall.index = df_basecall.index + \"_\" + df_basecall.nparts.astype(str)\n",
      "df_basecall.dir_output = df_basecall.dir_output + df_basecall.nparts.astype(str) + '/'\n",
      "df_basecall['basecalledDir'] = df_basecall.index + '/'\n",
      "df_basecall['guppy'] = config['guppy']\n",
      "df_basecall['model'] = config['model']\n",
      "for column in ['basecalledDir']:\n",
      "    df_basecall[column] = resultDir + 'step2_basecall/' + df_basecall[column]\n",
      "\n",
      "def parseDfToInput_basecall_splitH5(wildcard):\n",
      "    selfWildCardUnique = True\n",
      "    if isinstance(df_basecall.at[wildcard.sampleSplit, 'sample'], list):\n",
      "        selfWildCardUnique = False\n",
      "    if selfWildCardUnique:\n",
      "        return resultDir + 'step1_splitH5/' + df_basecall.at[wildcard.sampleSplit, 'sample'] + '.finished'\n",
      "    else:\n",
      "        return [resultDir + 'step1_splitH5/' + x + '.finished' for x in df_basecall.loc[wildcard.sampleSplit, 'sample']]\n",
      "\n",
      "def parseDfToParams_basecall_splitH5_need_h5(wildcard):\n",
      "    selfWildCardUnique = True\n",
      "    if isinstance(df_basecall.at[wildcard.sampleSplit, 'sample'], list):\n",
      "        selfWildCardUnique = False\n",
      "    if selfWildCardUnique:\n",
      "        fromSampleName = df_basecall.at[wildcard.sampleSplit, 'sample']\n",
      "        return df_splitH5.at[fromSampleName, 'need_h5']\n",
      "    else:\n",
      "        ls_fromSampleName = df_basecall.loc[wildcard.sampleSplit, 'sample']\n",
      "        return [df_splitH5.at[x, 'need_h5'] for x in ls_fromSampleName]\n",
      "\n",
      "\n",
      "## get parameter of rule `mergeFq` ##\n",
      "df_mergeFq = df_basecall.reset_index().groupby(\"sample\")[\"index\"].agg(list).pipe(\n",
      "    pd.DataFrame\n",
      ").rename(columns={\"index\": \"sampleSplit\"}).assign(dir_out=lambda df: df.index + \"/\")\n",
      "for column in ['dir_out']:\n",
      "    df_mergeFq[column] = resultDir + 'step3_mergeFq/' + df_mergeFq[column]\n",
      "\n",
      "def parseDfToInput_mergeFq_basecall(wildcard):\n",
      "    selfWildCardUnique = True\n",
      "    if isinstance(df_mergeFq.at[wildcard.sample, 'sampleSplit'], list):\n",
      "        selfWildCardUnique = False\n",
      "    if selfWildCardUnique:\n",
      "        return resultDir + 'step2_basecall/' + df_mergeFq.at[wildcard.sample, 'sampleSplit'] + '.finished'\n",
      "    else:\n",
      "        return [resultDir + 'step2_basecall/' + x + '.finished' for x in df_mergeFq.loc[wildcard.sample, 'sampleSplit']]\n",
      "\n",
      "def parseDfToParams_mergeFq_basecall_basecalledDir(wildcard):\n",
      "    selfWildCardUnique = True\n",
      "    if isinstance(df_mergeFq.at[wildcard.sample, 'sampleSplit'], list):\n",
      "        selfWildCardUnique = False\n",
      "    if selfWildCardUnique:\n",
      "        fromSampleName = df_mergeFq.at[wildcard.sample, 'sampleSplit']\n",
      "        return df_basecall.at[fromSampleName, 'basecalledDir']\n",
      "    else:\n",
      "        ls_fromSampleName = df_mergeFq.loc[wildcard.sample, 'sampleSplit']\n",
      "        return [df_basecall.at[x, 'basecalledDir'] for x in ls_fromSampleName]\n",
      "\n",
      "rule all:\n",
      "    input:\n",
      "        mergeFqFinished = [resultDir + 'step3_mergeFq/' + \"\" + sample + \".finished\" for sample in df_mergeFq.index],\n",
      "\n",
      "# parameter's dataframe of splitH5: \n",
      "# |     | need_h5   |   nparts | path                                                                                    | dir_output   |\n",
      "# |:----|:----------|---------:|:----------------------------------------------------------------------------------------|:-------------|\n",
      "# | all | False     |       12 | /scem/work/liuzj/projects/mouse/allFast5/20210723_1345_MN29338_FAQ41752_7386409e/fast5/ | all/         |\n",
      "rule splitH5:\n",
      "    input:\n",
      "        path = lambda wildcard: df_splitH5.at[wildcard.sample, 'path'],\n",
      "    output:\n",
      "        splitH5Finished = resultDir + 'step1_splitH5/' + '{sample}.finished',\n",
      "    params:\n",
      "        gpu = 0,\n",
      "        nparts = lambda wildcard: df_splitH5.at[wildcard.sample, 'nparts'],\n",
      "        dir_output = lambda wildcard: df_splitH5.at[wildcard.sample, 'dir_output'],\n",
      "    threads:1\n",
      "    priority:0\n",
      "    shell:\n",
      "        \"\"\"\n",
      "cd {pipelineDir}\n",
      "python ./splitFast5ToMultipleDir.py -i {input.path} -o {params.dir_output} -n {params.nparts}\n",
      "touch {output.splitH5Finished}\n",
      "        \"\"\"\n",
      "\n",
      "# parameter's dataframe of basecall: \n",
      "# |        |   nparts | dir_output   | sample   | basecalledDir   | guppy                                          | model                                                    |\n",
      "# |:-------|---------:|:-------------|:---------|:----------------|:-----------------------------------------------|:---------------------------------------------------------|\n",
      "# | all_0  |        0 | all/0/       | all      | all_0/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all_1  |        1 | all/1/       | all      | all_1/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all_2  |        2 | all/2/       | all      | all_2/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all_3  |        3 | all/3/       | all      | all_3/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all_4  |        4 | all/4/       | all      | all_4/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all_5  |        5 | all/5/       | all      | all_5/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all_6  |        6 | all/6/       | all      | all_6/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all_7  |        7 | all/7/       | all      | all_7/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all_8  |        8 | all/8/       | all      | all_8/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all_9  |        9 | all/9/       | all      | all_9/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all_10 |       10 | all/10/      | all      | all_10/         | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all_11 |       11 | all/11/      | all      | all_11/         | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "rule basecall:\n",
      "    input:\n",
      "        splitH5Finished = parseDfToInput_basecall_splitH5,\n",
      "    output:\n",
      "        basecallFinished = resultDir + 'step2_basecall/' + '{sampleSplit}.finished',\n",
      "    params:\n",
      "        gpu = 2,\n",
      "        need_h5 = parseDfToParams_basecall_splitH5_need_h5,\n",
      "        dir_output = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'dir_output'],\n",
      "        basecalledDir = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'basecalledDir'],\n",
      "        guppy = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'guppy'],\n",
      "        model = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'model'],\n",
      "    threads:18\n",
      "    priority:0\n",
      "    shell:\n",
      "        \"\"\"\n",
      "if [ {params.need_h5} = True ]\n",
      "then\n",
      "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings --fast5_out\n",
      "else\n",
      "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings\n",
      "fi\n",
      "touch {output.basecallFinished}\n",
      "        \"\"\"\n",
      "\n",
      "# parameter's dataframe of mergeFq: \n",
      "# | sample   | sampleSplit                                                                                                    | dir_out   |\n",
      "# |:---------|:---------------------------------------------------------------------------------------------------------------|:----------|\n",
      "# | all      | ['all_0', 'all_1', 'all_2', 'all_3', 'all_4', 'all_5', 'all_6', 'all_7', 'all_8', 'all_9', 'all_10', 'all_11'] | all/      |\n",
      "rule mergeFq:\n",
      "    input:\n",
      "        basecallFinished = parseDfToInput_mergeFq_basecall,\n",
      "    output:\n",
      "        mergeFqFinished = resultDir + 'step3_mergeFq/' + '{sample}.finished',\n",
      "    params:\n",
      "        gpu = 0,\n",
      "        basecalledDir = parseDfToParams_mergeFq_basecall_basecalledDir,\n",
      "        dir_out = lambda wildcard: df_mergeFq.at[wildcard.sample, 'dir_out'],\n",
      "    threads:18\n",
      "    priority:0\n",
      "    shell:\n",
      "        \"\"\"\n",
      "mkdir -p {params.dir_out}\n",
      "cd {pipelineDir}\n",
      "python mergeFastq.py {params.basecalledDir} -o {params.dir_out} -t {threads}\n",
      "touch {output.mergeFqFinished}\n",
      "        \"\"\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sf.getMain(path_sf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4906a907f3ce955ec173348abbed4e32ce81f1d00a5c31187a4d8f78431ced8f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
