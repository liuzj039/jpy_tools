{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:02:23.962509Z",
     "iopub.status.busy": "2021-09-27T06:02:23.961679Z",
     "iopub.status.idle": "2021-09-27T06:02:23.969535Z",
     "shell.execute_reply": "2021-09-27T06:02:23.967783Z",
     "shell.execute_reply.started": "2021-09-27T06:02:23.962432Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jpy_tools.parseSnake2 as jps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:02:25.377134Z",
     "iopub.status.busy": "2021-09-27T06:02:25.376340Z",
     "iopub.status.idle": "2021-09-27T06:02:25.384235Z",
     "shell.execute_reply": "2021-09-27T06:02:25.382519Z",
     "shell.execute_reply.started": "2021-09-27T06:02:25.377060Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_config = \"/public/home/liuzj/scripts/pipeline/basecallByGuppy/snakemake/config.yaml\"\n",
    "path_sf = \"/public/home/liuzj/scripts/pipeline/basecallByGuppy/snakemake/snakefile\"\n",
    "dir_scripts = \"/scem/work/liuzj/github/Liuzj_allScripts/pipeline/basecallByGuppy/scripts/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:02:26.253406Z",
     "iopub.status.busy": "2021-09-27T06:02:26.253017Z",
     "iopub.status.idle": "2021-09-27T06:02:26.260805Z",
     "shell.execute_reply": "2021-09-27T06:02:26.259311Z",
     "shell.execute_reply.started": "2021-09-27T06:02:26.253361Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sf = jps.SnakeFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:02:26.917889Z",
     "iopub.status.busy": "2021-09-27T06:02:26.917562Z",
     "iopub.status.idle": "2021-09-27T06:02:26.938332Z",
     "shell.execute_reply": "2021-09-27T06:02:26.937636Z",
     "shell.execute_reply.started": "2021-09-27T06:02:26.917861Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/public/home/liuzj/softwares/anaconda3/lib/python3.8/site-packages/jpy_tools/parseSnake2.py:93: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  self.yaml = yaml.load(open(self.path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import pandas as pd\n",
       "#configfile: \"/public/home/liuzj/scripts/pipeline/basecallByGuppy/snakemake/config.yaml\"\n",
       "pipelineDir = config['pipelineDir']\n",
       "resultDir = config[\"resultDir\"].rstrip(\"/\") + \"/\"\n",
       "pipelineDir = config[\"pipelineDir\"].rstrip(\"/\") + \"/\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = jps.SnakeHeader(sf, path_config)\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:02:31.184633Z",
     "iopub.status.busy": "2021-09-27T06:02:31.184269Z",
     "iopub.status.idle": "2021-09-27T06:02:31.189064Z",
     "shell.execute_reply": "2021-09-27T06:02:31.188183Z",
     "shell.execute_reply.started": "2021-09-27T06:02:31.184601Z"
    }
   },
   "outputs": [],
   "source": [
    "config = header.getConfig()\n",
    "resultDir = config[\"resultDir\"].rstrip(\"/\") + \"/\"\n",
    "pipelineDir = config[\"pipelineDir\"].rstrip(\"/\") + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:02:32.001452Z",
     "iopub.status.busy": "2021-09-27T06:02:32.001157Z",
     "iopub.status.idle": "2021-09-27T06:02:32.006267Z",
     "shell.execute_reply": "2021-09-27T06:02:32.005532Z",
     "shell.execute_reply.started": "2021-09-27T06:02:32.001424Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipelineDir': '/scem/work/liuzj/github/Liuzj_allScripts/pipeline/basecallByGuppy/scripts/',\n",
       " 'resultDir': '/scem/work/liuzj/projects/mouse/basecalledFastq/',\n",
       " 'guppy': '~/softwares/ont-guppy-4.2/bin/guppy_basecaller',\n",
       " 'model': '~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg',\n",
       " 'input': {'all': {'path': '/scem/work/liuzj/projects/mouse/allFast5/20210723_1345_MN29338_FAQ41752_7386409e/fast5/',\n",
       "   'nparts': 12,\n",
       "   'need_h5': False}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:02:46.863107Z",
     "iopub.status.busy": "2021-09-27T06:02:46.862540Z",
     "iopub.status.idle": "2021-09-27T06:02:46.897077Z",
     "shell.execute_reply": "2021-09-27T06:02:46.896207Z",
     "shell.execute_reply.started": "2021-09-27T06:02:46.863055Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dt_h5 = config['input']\n",
    "df_splitH5 = pd.DataFrame.from_dict(dt_h5).T\n",
    "df_splitH5['dir_output'] = df_splitH5.index + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:02:47.561925Z",
     "iopub.status.busy": "2021-09-27T06:02:47.561485Z",
     "iopub.status.idle": "2021-09-27T06:02:47.580418Z",
     "shell.execute_reply": "2021-09-27T06:02:47.579533Z",
     "shell.execute_reply.started": "2021-09-27T06:02:47.561885Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>need_h5</th>\n",
       "      <th>nparts</th>\n",
       "      <th>path</th>\n",
       "      <th>dir_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>/scem/work/liuzj/projects/mouse/allFast5/20210...</td>\n",
       "      <td>all/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    need_h5 nparts                                               path  \\\n",
       "all   False     12  /scem/work/liuzj/projects/mouse/allFast5/20210...   \n",
       "\n",
       "    dir_output  \n",
       "all       all/  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_splitH5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:03:00.301871Z",
     "iopub.status.busy": "2021-09-27T06:03:00.301423Z",
     "iopub.status.idle": "2021-09-27T06:03:00.312346Z",
     "shell.execute_reply": "2021-09-27T06:03:00.311572Z",
     "shell.execute_reply.started": "2021-09-27T06:03:00.301829Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 14:03:00.305 | INFO     | jpy_tools.parseSnake2:addRule:55 - splitH5 step num: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "## get parameter of rule `splitH5` ##\n",
       "import pandas as pd\n",
       "dt_h5 = config['input']\n",
       "df_splitH5 = pd.DataFrame.from_dict(dt_h5).T\n",
       "df_splitH5['dir_output'] = df_splitH5.index + '/'\n",
       "for column in ['dir_output']:\n",
       "    df_splitH5[column] = resultDir + 'step1_splitH5/' + df_splitH5[column]\n",
       "----------------\n",
       "IN RULE\n",
       "----------------\n",
       "rule splitH5:\n",
       "    input:\n",
       "        path = lambda wildcard: df_splitH5.at[wildcard.sample, 'path'],\n",
       "    output:\n",
       "        splitH5Finished = resultDir + 'step1_splitH5/' + '{sample}.finished',\n",
       "    params:\n",
       "        gpu = 0,\n",
       "        nparts = lambda wildcard: df_splitH5.at[wildcard.sample, 'nparts'],\n",
       "        dir_output = lambda wildcard: df_splitH5.at[wildcard.sample, 'dir_output'],\n",
       "    threads:1\n",
       "    priority:0\n",
       "    shell:\n",
       "        \"\"\"\n",
       "cd {pipelineDir}\n",
       "python ./splitFast5ToMultipleDir.py -i {input.path} -o {params.dir_output} -n {params.nparts}\n",
       "touch {output.splitH5Finished}\n",
       "        \"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_splitH5 = jps.SnakeRule(sf, 'splitH5', 1)\n",
    "rule_splitH5.addCode(\"\"\"\n",
    "import pandas as pd\n",
    "dt_h5 = config['input']\n",
    "df_splitH5 = pd.DataFrame.from_dict(dt_h5).T\n",
    "df_splitH5['dir_output'] = df_splitH5.index + '/'\n",
    "\"\"\")\n",
    "rule_splitH5.addMetaDf('df_splitH5', ['dir_output'])\n",
    "rule_splitH5.addMain('input', ['path'])\n",
    "rule_splitH5.addMain('params', ['nparts', 'dir_output'])\n",
    "rule_splitH5.setShell(\"\"\"\n",
    "cd {pipelineDir}\n",
    "python ./splitFast5ToMultipleDir.py -i {input.path} -o {params.dir_output} -n {params.nparts}\n",
    "\"\"\")\n",
    "rule_splitH5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:03:11.381073Z",
     "iopub.status.busy": "2021-09-27T06:03:11.380649Z",
     "iopub.status.idle": "2021-09-27T06:03:11.402602Z",
     "shell.execute_reply": "2021-09-27T06:03:11.401658Z",
     "shell.execute_reply.started": "2021-09-27T06:03:11.381033Z"
    }
   },
   "outputs": [],
   "source": [
    "df_basecall = df_splitH5.copy()\n",
    "df_basecall[\"nparts\"] = df_basecall[\"nparts\"].map(lambda x: list(range(x)))\n",
    "df_basecall = df_basecall.explode(\"nparts\")\n",
    "df_basecall = df_basecall[[\"nparts\", \"dir_output\"]]\n",
    "df_basecall['sample'] = df_basecall.index\n",
    "df_basecall.index = df_basecall.index + df_basecall.nparts.astype(str)\n",
    "df_basecall.dir_output = df_basecall.dir_output + df_basecall.nparts.astype(str) + '/'\n",
    "df_basecall['basecalledDir'] = df_basecall.index + '/'\n",
    "df_basecall['guppy'] = config['guppy']\n",
    "df_basecall['model'] = config['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:03:11.861385Z",
     "iopub.status.busy": "2021-09-27T06:03:11.861014Z",
     "iopub.status.idle": "2021-09-27T06:03:11.880942Z",
     "shell.execute_reply": "2021-09-27T06:03:11.880033Z",
     "shell.execute_reply.started": "2021-09-27T06:03:11.861349Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nparts</th>\n",
       "      <th>dir_output</th>\n",
       "      <th>sample</th>\n",
       "      <th>basecalledDir</th>\n",
       "      <th>guppy</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all0</th>\n",
       "      <td>0</td>\n",
       "      <td>all/0/</td>\n",
       "      <td>all</td>\n",
       "      <td>all0/</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/bin/guppy_basecaller</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all1</th>\n",
       "      <td>1</td>\n",
       "      <td>all/1/</td>\n",
       "      <td>all</td>\n",
       "      <td>all1/</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/bin/guppy_basecaller</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all2</th>\n",
       "      <td>2</td>\n",
       "      <td>all/2/</td>\n",
       "      <td>all</td>\n",
       "      <td>all2/</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/bin/guppy_basecaller</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all3</th>\n",
       "      <td>3</td>\n",
       "      <td>all/3/</td>\n",
       "      <td>all</td>\n",
       "      <td>all3/</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/bin/guppy_basecaller</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all4</th>\n",
       "      <td>4</td>\n",
       "      <td>all/4/</td>\n",
       "      <td>all</td>\n",
       "      <td>all4/</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/bin/guppy_basecaller</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all5</th>\n",
       "      <td>5</td>\n",
       "      <td>all/5/</td>\n",
       "      <td>all</td>\n",
       "      <td>all5/</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/bin/guppy_basecaller</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all6</th>\n",
       "      <td>6</td>\n",
       "      <td>all/6/</td>\n",
       "      <td>all</td>\n",
       "      <td>all6/</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/bin/guppy_basecaller</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all7</th>\n",
       "      <td>7</td>\n",
       "      <td>all/7/</td>\n",
       "      <td>all</td>\n",
       "      <td>all7/</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/bin/guppy_basecaller</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all8</th>\n",
       "      <td>8</td>\n",
       "      <td>all/8/</td>\n",
       "      <td>all</td>\n",
       "      <td>all8/</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/bin/guppy_basecaller</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all9</th>\n",
       "      <td>9</td>\n",
       "      <td>all/9/</td>\n",
       "      <td>all</td>\n",
       "      <td>all9/</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/bin/guppy_basecaller</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all10</th>\n",
       "      <td>10</td>\n",
       "      <td>all/10/</td>\n",
       "      <td>all</td>\n",
       "      <td>all10/</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/bin/guppy_basecaller</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all11</th>\n",
       "      <td>11</td>\n",
       "      <td>all/11/</td>\n",
       "      <td>all</td>\n",
       "      <td>all11/</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/bin/guppy_basecaller</td>\n",
       "      <td>~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nparts dir_output sample basecalledDir  \\\n",
       "all0       0     all/0/    all         all0/   \n",
       "all1       1     all/1/    all         all1/   \n",
       "all2       2     all/2/    all         all2/   \n",
       "all3       3     all/3/    all         all3/   \n",
       "all4       4     all/4/    all         all4/   \n",
       "all5       5     all/5/    all         all5/   \n",
       "all6       6     all/6/    all         all6/   \n",
       "all7       7     all/7/    all         all7/   \n",
       "all8       8     all/8/    all         all8/   \n",
       "all9       9     all/9/    all         all9/   \n",
       "all10     10    all/10/    all        all10/   \n",
       "all11     11    all/11/    all        all11/   \n",
       "\n",
       "                                                guppy  \\\n",
       "all0   ~/softwares/ont-guppy-4.2/bin/guppy_basecaller   \n",
       "all1   ~/softwares/ont-guppy-4.2/bin/guppy_basecaller   \n",
       "all2   ~/softwares/ont-guppy-4.2/bin/guppy_basecaller   \n",
       "all3   ~/softwares/ont-guppy-4.2/bin/guppy_basecaller   \n",
       "all4   ~/softwares/ont-guppy-4.2/bin/guppy_basecaller   \n",
       "all5   ~/softwares/ont-guppy-4.2/bin/guppy_basecaller   \n",
       "all6   ~/softwares/ont-guppy-4.2/bin/guppy_basecaller   \n",
       "all7   ~/softwares/ont-guppy-4.2/bin/guppy_basecaller   \n",
       "all8   ~/softwares/ont-guppy-4.2/bin/guppy_basecaller   \n",
       "all9   ~/softwares/ont-guppy-4.2/bin/guppy_basecaller   \n",
       "all10  ~/softwares/ont-guppy-4.2/bin/guppy_basecaller   \n",
       "all11  ~/softwares/ont-guppy-4.2/bin/guppy_basecaller   \n",
       "\n",
       "                                                   model  \n",
       "all0   ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...  \n",
       "all1   ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...  \n",
       "all2   ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...  \n",
       "all3   ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...  \n",
       "all4   ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...  \n",
       "all5   ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...  \n",
       "all6   ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...  \n",
       "all7   ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...  \n",
       "all8   ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...  \n",
       "all9   ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...  \n",
       "all10  ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...  \n",
       "all11  ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450b...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_basecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:04:03.223359Z",
     "iopub.status.busy": "2021-09-27T06:04:03.223005Z",
     "iopub.status.idle": "2021-09-27T06:04:03.233199Z",
     "shell.execute_reply": "2021-09-27T06:04:03.232545Z",
     "shell.execute_reply.started": "2021-09-27T06:04:03.223327Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 14:04:03.226 | INFO     | jpy_tools.parseSnake2:addRule:55 - basecall step num: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "## get parameter of rule `basecall` ##\n",
       "df_basecall = df_splitH5.copy()\n",
       "df_basecall[\"nparts\"] = df_basecall[\"nparts\"].map(lambda x: list(range(x)))\n",
       "df_basecall = df_basecall.explode(\"nparts\")\n",
       "df_basecall = df_basecall[[\"nparts\", \"dir_output\"]]\n",
       "df_basecall['sample'] = df_basecall.index\n",
       "df_basecall.index = df_basecall.index + df_basecall.nparts.astype(str)\n",
       "df_basecall.dir_output = df_basecall.dir_output + df_basecall.nparts.astype(str) + '/'\n",
       "df_basecall['basecalledDir'] = df_basecall.index + '/'\n",
       "df_basecall['guppy'] = config['guppy']\n",
       "df_basecall['model'] = config['model']\n",
       "for column in ['basecalledDir']:\n",
       "    df_basecall[column] = resultDir + 'step2_basecall/' + df_basecall[column]\n",
       "\n",
       "def parseDfToInput_basecall_splitH5(wildcard):\n",
       "    selfWildCardUnique = True\n",
       "    if isinstance(df_basecall.at[wildcard.sampleSplit, 'sample'], list):\n",
       "        selfWildCardUnique = False\n",
       "    if selfWildCardUnique:\n",
       "        return resultDir + 'step1_splitH5/' + df_basecall.at[wildcard.sampleSplit, 'sample'] + '.finished'\n",
       "    else:\n",
       "        return [resultDir + 'step1_splitH5/' + x + '.finished' for x in df_basecall.loc[wildcard.sampleSplit, 'sample']]\n",
       "\n",
       "def parseDfToParams_basecall_splitH5_need_h5(wildcard):\n",
       "    selfWildCardUnique = True\n",
       "    if isinstance(df_basecall.at[wildcard.sampleSplit, 'sample'], list):\n",
       "        selfWildCardUnique = False\n",
       "    if selfWildCardUnique:\n",
       "        fromSampleName = df_basecall.at[wildcard.sampleSplit, 'sample']\n",
       "        return df_splitH5.at[fromSampleName, 'need_h5']\n",
       "    else:\n",
       "        ls_fromSampleName = df_basecall.loc[wildcard.sampleSplit, 'sample']\n",
       "        return [df_splitH5.at[x, 'need_h5'] for x in ls_fromSampleName]\n",
       "----------------\n",
       "IN RULE\n",
       "----------------\n",
       "rule basecall:\n",
       "    input:\n",
       "        splitH5Finished = parseDfToInput_basecall_splitH5,\n",
       "    output:\n",
       "        basecallFinished = resultDir + 'step2_basecall/' + '{sampleSplit}.finished',\n",
       "    params:\n",
       "        gpu = 2,\n",
       "        need_h5 = parseDfToParams_basecall_splitH5_need_h5,\n",
       "        dir_output = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'dir_output'],\n",
       "        basecalledDir = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'basecalledDir'],\n",
       "        guppy = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'guppy'],\n",
       "        model = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'model'],\n",
       "    threads:18\n",
       "    priority:0\n",
       "    shell:\n",
       "        \"\"\"\n",
       "if [ {params.need_h5} = True ]\n",
       "then\n",
       "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings --fast5_out\n",
       "else\n",
       "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings\n",
       "fi\n",
       "touch {output.basecallFinished}\n",
       "        \"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_basecall = jps.SnakeRule(sf, \"basecall\", 18, 2, wildCard=\"sampleSplit\")\n",
    "rule_basecall.addCode(\n",
    "    \"\"\"\n",
    "df_basecall = df_splitH5.copy()\n",
    "df_basecall[\"nparts\"] = df_basecall[\"nparts\"].map(lambda x: list(range(x)))\n",
    "df_basecall = df_basecall.explode(\"nparts\")\n",
    "df_basecall = df_basecall[[\"nparts\", \"dir_output\"]]\n",
    "df_basecall['sample'] = df_basecall.index\n",
    "df_basecall.index = df_basecall.index + df_basecall.nparts.astype(str)\n",
    "df_basecall.dir_output = df_basecall.dir_output + df_basecall.nparts.astype(str) + '/'\n",
    "df_basecall['basecalledDir'] = df_basecall.index + '/'\n",
    "df_basecall['guppy'] = config['guppy']\n",
    "df_basecall['model'] = config['model']\n",
    "\"\"\"\n",
    ")\n",
    "rule_basecall.addMetaDf(\"df_basecall\", [\"basecalledDir\"])\n",
    "rule_basecall.addMain(\"params\", [\"need_h5\"], rule_splitH5)\n",
    "rule_basecall.addMain(\"params\", [\"dir_output\", \"basecalledDir\", \"guppy\", \"model\"])\n",
    "\n",
    "rule_basecall.setShell(\"\"\"\n",
    "if [ {params.need_h5} = True ]\n",
    "then\n",
    "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings --fast5_out\n",
    "else\n",
    "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings\n",
    "fi\n",
    "\"\"\")\n",
    "rule_basecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:18:41.666330Z",
     "iopub.status.busy": "2021-09-27T06:18:41.665853Z",
     "iopub.status.idle": "2021-09-27T06:18:41.679771Z",
     "shell.execute_reply": "2021-09-27T06:18:41.678686Z",
     "shell.execute_reply.started": "2021-09-27T06:18:41.666287Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mergeFq = df_basecall.reset_index().groupby(\"sample\")[\"index\"].agg(list).pipe(\n",
    "    pd.DataFrame\n",
    ").rename(columns={\"index\": \"sampleSplit\"}).assign(dir_out=lambda df: df.index + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:18:42.032717Z",
     "iopub.status.busy": "2021-09-27T06:18:42.032338Z",
     "iopub.status.idle": "2021-09-27T06:18:42.044401Z",
     "shell.execute_reply": "2021-09-27T06:18:42.043329Z",
     "shell.execute_reply.started": "2021-09-27T06:18:42.032682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampleSplit</th>\n",
       "      <th>dir_out</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>[all0, all1, all2, all3, all4, all5, all6, all...</td>\n",
       "      <td>all/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sampleSplit dir_out\n",
       "sample                                                           \n",
       "all     [all0, all1, all2, all3, all4, all5, all6, all...    all/"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mergeFq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:18:50.489483Z",
     "iopub.status.busy": "2021-09-27T06:18:50.489163Z",
     "iopub.status.idle": "2021-09-27T06:18:50.499162Z",
     "shell.execute_reply": "2021-09-27T06:18:50.498414Z",
     "shell.execute_reply.started": "2021-09-27T06:18:50.489454Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 14:18:50.492 | INFO     | jpy_tools.parseSnake2:addRule:55 - mergeFq step num: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "## get parameter of rule `mergeFq` ##\n",
       "df_mergeFq = df_basecall.reset_index().groupby(\"sample\")[\"index\"].agg(list).pipe(\n",
       "    pd.DataFrame\n",
       ").rename(columns={\"index\": \"sampleSplit\"}).assign(dir_out=lambda df: df.index + \"/\")\n",
       "for column in ['dir_out']:\n",
       "    df_mergeFq[column] = resultDir + 'step3_mergeFq/' + df_mergeFq[column]\n",
       "\n",
       "def parseDfToInput_mergeFq_basecall(wildcard):\n",
       "    selfWildCardUnique = True\n",
       "    if isinstance(df_mergeFq.at[wildcard.sample, 'sampleSplit'], list):\n",
       "        selfWildCardUnique = False\n",
       "    if selfWildCardUnique:\n",
       "        return resultDir + 'step2_basecall/' + df_mergeFq.at[wildcard.sample, 'sampleSplit'] + '.finished'\n",
       "    else:\n",
       "        return [resultDir + 'step2_basecall/' + x + '.finished' for x in df_mergeFq.loc[wildcard.sample, 'sampleSplit']]\n",
       "\n",
       "def parseDfToParams_mergeFq_basecall_basecalledDir(wildcard):\n",
       "    selfWildCardUnique = True\n",
       "    if isinstance(df_mergeFq.at[wildcard.sample, 'sampleSplit'], list):\n",
       "        selfWildCardUnique = False\n",
       "    if selfWildCardUnique:\n",
       "        fromSampleName = df_mergeFq.at[wildcard.sample, 'sampleSplit']\n",
       "        return df_basecall.at[fromSampleName, 'basecalledDir']\n",
       "    else:\n",
       "        ls_fromSampleName = df_mergeFq.loc[wildcard.sample, 'sampleSplit']\n",
       "        return [df_basecall.at[x, 'basecalledDir'] for x in ls_fromSampleName]\n",
       "----------------\n",
       "IN RULE\n",
       "----------------\n",
       "rule mergeFq:\n",
       "    input:\n",
       "        basecallFinished = parseDfToInput_mergeFq_basecall,\n",
       "    output:\n",
       "        mergeFqFinished = resultDir + 'step3_mergeFq/' + '{sample}.finished',\n",
       "    params:\n",
       "        gpu = 0,\n",
       "        basecalledDir = parseDfToParams_mergeFq_basecall_basecalledDir,\n",
       "        dir_out = lambda wildcard: df_mergeFq.at[wildcard.sample, 'dir_out'],\n",
       "    threads:18\n",
       "    priority:0\n",
       "    shell:\n",
       "        \"\"\"\n",
       "cd {pipelineDir}\n",
       "python mergeFastq.py {params.basecalledDir} -o {params.dir_out} -t {threads}\n",
       "touch {output.mergeFqFinished}\n",
       "        \"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_mergeFq = jps.SnakeRule(sf, 'mergeFq', 18, 0)\n",
    "rule_mergeFq.addCode(\"\"\"\n",
    "df_mergeFq = df_basecall.reset_index().groupby(\"sample\")[\"index\"].agg(list).pipe(\n",
    "    pd.DataFrame\n",
    ").rename(columns={\"index\": \"sampleSplit\"}).assign(dir_out=lambda df: df.index + \"/\")\n",
    "\"\"\")\n",
    "rule_mergeFq.addMetaDf('df_mergeFq', ['dir_out'])\n",
    "rule_mergeFq.addMain('params', ['basecalledDir'], fromRule=rule_basecall)\n",
    "rule_mergeFq.addMain('params', ['dir_out'])\n",
    "rule_mergeFq.setShell(\"\"\"\n",
    "mkdir -p {params.dir_out}\n",
    "cd {pipelineDir}\n",
    "python mergeFastq.py {params.basecalledDir} -o {params.dir_out} -t {threads}\n",
    "\"\"\")\n",
    "rule_mergeFq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:19:30.784692Z",
     "iopub.status.busy": "2021-09-27T06:19:30.784354Z",
     "iopub.status.idle": "2021-09-27T06:19:30.790717Z",
     "shell.execute_reply": "2021-09-27T06:19:30.789605Z",
     "shell.execute_reply.started": "2021-09-27T06:19:30.784662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rule all:\n",
       "    input:\n",
       "        mergeFqFinished = [resultDir + 'step3_mergeFq/' + \"\" + sample + \".finished\" for sample in df_mergeFq.index],"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_all = jps.SnakeAll(sf, rule_mergeFq)\n",
    "rule_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T06:19:33.979261Z",
     "iopub.status.busy": "2021-09-27T06:19:33.978885Z",
     "iopub.status.idle": "2021-09-27T06:19:33.986536Z",
     "shell.execute_reply": "2021-09-27T06:19:33.985601Z",
     "shell.execute_reply.started": "2021-09-27T06:19:33.979224Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "#configfile: \"/public/home/liuzj/scripts/pipeline/basecallByGuppy/snakemake/config.yaml\"\n",
      "pipelineDir = config['pipelineDir']\n",
      "resultDir = config[\"resultDir\"].rstrip(\"/\") + \"/\"\n",
      "pipelineDir = config[\"pipelineDir\"].rstrip(\"/\") + \"/\"\n",
      "\n",
      "\n",
      "## get parameter of rule `splitH5` ##\n",
      "import pandas as pd\n",
      "dt_h5 = config['input']\n",
      "df_splitH5 = pd.DataFrame.from_dict(dt_h5).T\n",
      "df_splitH5['dir_output'] = df_splitH5.index + '/'\n",
      "for column in ['dir_output']:\n",
      "    df_splitH5[column] = resultDir + 'step1_splitH5/' + df_splitH5[column]\n",
      "\n",
      "\n",
      "## get parameter of rule `basecall` ##\n",
      "df_basecall = df_splitH5.copy()\n",
      "df_basecall[\"nparts\"] = df_basecall[\"nparts\"].map(lambda x: list(range(x)))\n",
      "df_basecall = df_basecall.explode(\"nparts\")\n",
      "df_basecall = df_basecall[[\"nparts\", \"dir_output\"]]\n",
      "df_basecall['sample'] = df_basecall.index\n",
      "df_basecall.index = df_basecall.index + df_basecall.nparts.astype(str)\n",
      "df_basecall.dir_output = df_basecall.dir_output + df_basecall.nparts.astype(str) + '/'\n",
      "df_basecall['basecalledDir'] = df_basecall.index + '/'\n",
      "df_basecall['guppy'] = config['guppy']\n",
      "df_basecall['model'] = config['model']\n",
      "for column in ['basecalledDir']:\n",
      "    df_basecall[column] = resultDir + 'step2_basecall/' + df_basecall[column]\n",
      "\n",
      "def parseDfToInput_basecall_splitH5(wildcard):\n",
      "    selfWildCardUnique = True\n",
      "    if isinstance(df_basecall.at[wildcard.sampleSplit, 'sample'], list):\n",
      "        selfWildCardUnique = False\n",
      "    if selfWildCardUnique:\n",
      "        return resultDir + 'step1_splitH5/' + df_basecall.at[wildcard.sampleSplit, 'sample'] + '.finished'\n",
      "    else:\n",
      "        return [resultDir + 'step1_splitH5/' + x + '.finished' for x in df_basecall.loc[wildcard.sampleSplit, 'sample']]\n",
      "\n",
      "def parseDfToParams_basecall_splitH5_need_h5(wildcard):\n",
      "    selfWildCardUnique = True\n",
      "    if isinstance(df_basecall.at[wildcard.sampleSplit, 'sample'], list):\n",
      "        selfWildCardUnique = False\n",
      "    if selfWildCardUnique:\n",
      "        fromSampleName = df_basecall.at[wildcard.sampleSplit, 'sample']\n",
      "        return df_splitH5.at[fromSampleName, 'need_h5']\n",
      "    else:\n",
      "        ls_fromSampleName = df_basecall.loc[wildcard.sampleSplit, 'sample']\n",
      "        return [df_splitH5.at[x, 'need_h5'] for x in ls_fromSampleName]\n",
      "\n",
      "\n",
      "## get parameter of rule `mergeFq` ##\n",
      "df_mergeFq = df_basecall.reset_index().groupby(\"sample\")[\"index\"].agg(list).pipe(\n",
      "    pd.DataFrame\n",
      ").rename(columns={\"index\": \"sampleSplit\"}).assign(dir_out=lambda df: df.index + \"/\")\n",
      "for column in ['dir_out']:\n",
      "    df_mergeFq[column] = resultDir + 'step3_mergeFq/' + df_mergeFq[column]\n",
      "\n",
      "def parseDfToInput_mergeFq_basecall(wildcard):\n",
      "    selfWildCardUnique = True\n",
      "    if isinstance(df_mergeFq.at[wildcard.sample, 'sampleSplit'], list):\n",
      "        selfWildCardUnique = False\n",
      "    if selfWildCardUnique:\n",
      "        return resultDir + 'step2_basecall/' + df_mergeFq.at[wildcard.sample, 'sampleSplit'] + '.finished'\n",
      "    else:\n",
      "        return [resultDir + 'step2_basecall/' + x + '.finished' for x in df_mergeFq.loc[wildcard.sample, 'sampleSplit']]\n",
      "\n",
      "def parseDfToParams_mergeFq_basecall_basecalledDir(wildcard):\n",
      "    selfWildCardUnique = True\n",
      "    if isinstance(df_mergeFq.at[wildcard.sample, 'sampleSplit'], list):\n",
      "        selfWildCardUnique = False\n",
      "    if selfWildCardUnique:\n",
      "        fromSampleName = df_mergeFq.at[wildcard.sample, 'sampleSplit']\n",
      "        return df_basecall.at[fromSampleName, 'basecalledDir']\n",
      "    else:\n",
      "        ls_fromSampleName = df_mergeFq.loc[wildcard.sample, 'sampleSplit']\n",
      "        return [df_basecall.at[x, 'basecalledDir'] for x in ls_fromSampleName]\n",
      "\n",
      "rule all:\n",
      "    input:\n",
      "        mergeFqFinished = [resultDir + 'step3_mergeFq/' + \"\" + sample + \".finished\" for sample in df_mergeFq.index],\n",
      "\n",
      "rule splitH5:\n",
      "    input:\n",
      "        path = lambda wildcard: df_splitH5.at[wildcard.sample, 'path'],\n",
      "    output:\n",
      "        splitH5Finished = resultDir + 'step1_splitH5/' + '{sample}.finished',\n",
      "    params:\n",
      "        gpu = 0,\n",
      "        nparts = lambda wildcard: df_splitH5.at[wildcard.sample, 'nparts'],\n",
      "        dir_output = lambda wildcard: df_splitH5.at[wildcard.sample, 'dir_output'],\n",
      "    threads:1\n",
      "    priority:0\n",
      "    shell:\n",
      "        \"\"\"\n",
      "cd {pipelineDir}\n",
      "python ./splitFast5ToMultipleDir.py -i {input.path} -o {params.dir_output} -n {params.nparts}\n",
      "touch {output.splitH5Finished}\n",
      "        \"\"\"\n",
      "\n",
      "rule basecall:\n",
      "    input:\n",
      "        splitH5Finished = parseDfToInput_basecall_splitH5,\n",
      "    output:\n",
      "        basecallFinished = resultDir + 'step2_basecall/' + '{sampleSplit}.finished',\n",
      "    params:\n",
      "        gpu = 2,\n",
      "        need_h5 = parseDfToParams_basecall_splitH5_need_h5,\n",
      "        dir_output = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'dir_output'],\n",
      "        basecalledDir = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'basecalledDir'],\n",
      "        guppy = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'guppy'],\n",
      "        model = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'model'],\n",
      "    threads:18\n",
      "    priority:0\n",
      "    shell:\n",
      "        \"\"\"\n",
      "if [ {params.need_h5} = True ]\n",
      "then\n",
      "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings --fast5_out\n",
      "else\n",
      "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings\n",
      "fi\n",
      "touch {output.basecallFinished}\n",
      "        \"\"\"\n",
      "\n",
      "rule mergeFq:\n",
      "    input:\n",
      "        basecallFinished = parseDfToInput_mergeFq_basecall,\n",
      "    output:\n",
      "        mergeFqFinished = resultDir + 'step3_mergeFq/' + '{sample}.finished',\n",
      "    params:\n",
      "        gpu = 0,\n",
      "        basecalledDir = parseDfToParams_mergeFq_basecall_basecalledDir,\n",
      "        dir_out = lambda wildcard: df_mergeFq.at[wildcard.sample, 'dir_out'],\n",
      "    threads:18\n",
      "    priority:0\n",
      "    shell:\n",
      "        \"\"\"\n",
      "cd {pipelineDir}\n",
      "python mergeFastq.py {params.basecalledDir} -o {params.dir_out} -t {threads}\n",
      "touch {output.mergeFqFinished}\n",
      "        \"\"\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sf.getMain(path_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4906a907f3ce955ec173348abbed4e32ce81f1d00a5c31187a4d8f78431ced8f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
