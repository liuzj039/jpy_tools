{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:17:43.337373Z",
     "iopub.status.busy": "2021-09-27T07:17:43.336689Z",
     "iopub.status.idle": "2021-09-27T07:17:45.673090Z",
     "shell.execute_reply": "2021-09-27T07:17:45.671976Z",
     "shell.execute_reply.started": "2021-09-27T07:17:43.337237Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jpy_tools.parseSnake2 as jps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:17:45.675232Z",
     "iopub.status.busy": "2021-09-27T07:17:45.674848Z",
     "iopub.status.idle": "2021-09-27T07:17:45.679608Z",
     "shell.execute_reply": "2021-09-27T07:17:45.678716Z",
     "shell.execute_reply.started": "2021-09-27T07:17:45.675197Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_config = \"/public/home/liuzj/scripts/pipeline/basecallByGuppy/snakemake/config.yaml\"\n",
    "path_sf = \"/public/home/liuzj/scripts/pipeline/basecallByGuppy/snakemake/snakefile\"\n",
    "dir_scripts = \"/scem/work/liuzj/github/Liuzj_allScripts/pipeline/basecallByGuppy/scripts/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:17:45.681950Z",
     "iopub.status.busy": "2021-09-27T07:17:45.681576Z",
     "iopub.status.idle": "2021-09-27T07:17:45.685566Z",
     "shell.execute_reply": "2021-09-27T07:17:45.684632Z",
     "shell.execute_reply.started": "2021-09-27T07:17:45.681917Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sf = jps.SnakeFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:17:45.687518Z",
     "iopub.status.busy": "2021-09-27T07:17:45.687165Z",
     "iopub.status.idle": "2021-09-27T07:17:45.701543Z",
     "shell.execute_reply": "2021-09-27T07:17:45.700685Z",
     "shell.execute_reply.started": "2021-09-27T07:17:45.687485Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/public/home/liuzj/softwares/anaconda3/lib/python3.8/site-packages/jpy_tools/parseSnake2.py:93: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  self.yaml = yaml.load(open(self.path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import pandas as pd\n",
       "#configfile: \"/public/home/liuzj/scripts/pipeline/basecallByGuppy/snakemake/config.yaml\"\n",
       "pipelineDir = config['pipelineDir']\n",
       "resultDir = config[\"resultDir\"].rstrip(\"/\") + \"/\"\n",
       "pipelineDir = config[\"pipelineDir\"].rstrip(\"/\") + \"/\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = jps.SnakeHeader(sf, path_config)\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:17:45.703188Z",
     "iopub.status.busy": "2021-09-27T07:17:45.702830Z",
     "iopub.status.idle": "2021-09-27T07:17:45.707840Z",
     "shell.execute_reply": "2021-09-27T07:17:45.706848Z",
     "shell.execute_reply.started": "2021-09-27T07:17:45.703155Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = header.getConfig()\n",
    "resultDir = config[\"resultDir\"].rstrip(\"/\") + \"/\"\n",
    "pipelineDir = config[\"pipelineDir\"].rstrip(\"/\") + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:17:45.709435Z",
     "iopub.status.busy": "2021-09-27T07:17:45.709081Z",
     "iopub.status.idle": "2021-09-27T07:17:45.715173Z",
     "shell.execute_reply": "2021-09-27T07:17:45.714227Z",
     "shell.execute_reply.started": "2021-09-27T07:17:45.709403Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipelineDir': '/scem/work/liuzj/github/Liuzj_allScripts/pipeline/basecallByGuppy/scripts/',\n",
       " 'resultDir': '/scem/work/liuzj/projects/mouse/basecalledFastq/',\n",
       " 'guppy': '~/softwares/ont-guppy-4.2/bin/guppy_basecaller',\n",
       " 'model': '~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg',\n",
       " 'input': {'all': {'path': '/scem/work/liuzj/projects/mouse/allFast5/20210723_1345_MN29338_FAQ41752_7386409e/fast5/',\n",
       "   'nparts': 12,\n",
       "   'need_h5': False}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:17:45.716792Z",
     "iopub.status.busy": "2021-09-27T07:17:45.716434Z",
     "iopub.status.idle": "2021-09-27T07:17:45.733076Z",
     "shell.execute_reply": "2021-09-27T07:17:45.732153Z",
     "shell.execute_reply.started": "2021-09-27T07:17:45.716759Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dt_h5 = config['input']\n",
    "df_splitH5 = pd.DataFrame.from_dict(dt_h5).T\n",
    "df_splitH5['dir_output'] = df_splitH5.index + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:17:45.735635Z",
     "iopub.status.busy": "2021-09-27T07:17:45.735142Z",
     "iopub.status.idle": "2021-09-27T07:17:45.753215Z",
     "shell.execute_reply": "2021-09-27T07:17:45.752417Z",
     "shell.execute_reply.started": "2021-09-27T07:17:45.735602Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 15:17:45.740 | INFO     | jpy_tools.parseSnake2:addRule:55 - splitH5 step num: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "## get parameter of rule `splitH5` ##\n",
       "import pandas as pd\n",
       "dt_h5 = config['input']\n",
       "df_splitH5 = pd.DataFrame.from_dict(dt_h5).T\n",
       "df_splitH5['dir_output'] = df_splitH5.index + '/'\n",
       "for column in ['dir_output']:\n",
       "    df_splitH5[column] = resultDir + 'step1_splitH5/' + df_splitH5[column]\n",
       "----------------\n",
       "IN RULE\n",
       "----------------\n",
       "# parameter's dataframe of splitH5: \n",
       "# |     | need_h5   |   nparts | path                                                                                    | dir_output   |\n",
       "# |:----|:----------|---------:|:----------------------------------------------------------------------------------------|:-------------|\n",
       "# | all | False     |       12 | /scem/work/liuzj/projects/mouse/allFast5/20210723_1345_MN29338_FAQ41752_7386409e/fast5/ | all/         |\n",
       "rule splitH5:\n",
       "    input:\n",
       "        path = lambda wildcard: df_splitH5.at[wildcard.sample, 'path'],\n",
       "    output:\n",
       "        splitH5Finished = resultDir + 'step1_splitH5/' + '{sample}.finished',\n",
       "    params:\n",
       "        gpu = 0,\n",
       "        nparts = lambda wildcard: df_splitH5.at[wildcard.sample, 'nparts'],\n",
       "        dir_output = lambda wildcard: df_splitH5.at[wildcard.sample, 'dir_output'],\n",
       "    threads:1\n",
       "    priority:0\n",
       "    shell:\n",
       "        \"\"\"\n",
       "cd {pipelineDir}\n",
       "python ./splitFast5ToMultipleDir.py -i {input.path} -o {params.dir_output} -n {params.nparts}\n",
       "touch {output.splitH5Finished}\n",
       "        \"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_splitH5 = jps.SnakeRule(sf, 'splitH5', 1)\n",
    "rule_splitH5.addCode(\"\"\"\n",
    "import pandas as pd\n",
    "dt_h5 = config['input']\n",
    "df_splitH5 = pd.DataFrame.from_dict(dt_h5).T\n",
    "df_splitH5['dir_output'] = df_splitH5.index + '/'\n",
    "\"\"\")\n",
    "rule_splitH5.addMetaDf('df_splitH5', ['dir_output'], df_splitH5)\n",
    "rule_splitH5.addMain('input', ['path'])\n",
    "rule_splitH5.addMain('params', ['nparts', 'dir_output'])\n",
    "rule_splitH5.setShell(\"\"\"\n",
    "cd {pipelineDir}\n",
    "python ./splitFast5ToMultipleDir.py -i {input.path} -o {params.dir_output} -n {params.nparts}\n",
    "\"\"\")\n",
    "rule_splitH5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:18:09.330252Z",
     "iopub.status.busy": "2021-09-27T07:18:09.329719Z",
     "iopub.status.idle": "2021-09-27T07:18:09.358729Z",
     "shell.execute_reply": "2021-09-27T07:18:09.357556Z",
     "shell.execute_reply.started": "2021-09-27T07:18:09.330204Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_basecall = df_splitH5.copy()\n",
    "df_basecall[\"nparts\"] = df_basecall[\"nparts\"].map(lambda x: list(range(x)))\n",
    "df_basecall = df_basecall.explode(\"nparts\")\n",
    "df_basecall = df_basecall[[\"nparts\", \"dir_output\"]]\n",
    "df_basecall['sample'] = df_basecall.index\n",
    "df_basecall.index = df_basecall.index + df_basecall.nparts.astype(str)\n",
    "df_basecall.dir_output = df_basecall.dir_output + df_basecall.nparts.astype(str) + '/'\n",
    "df_basecall['basecalledDir'] = df_basecall.index + '/'\n",
    "df_basecall['guppy'] = config['guppy']\n",
    "df_basecall['model'] = config['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:18:27.375689Z",
     "iopub.status.busy": "2021-09-27T07:18:27.375238Z",
     "iopub.status.idle": "2021-09-27T07:18:27.396929Z",
     "shell.execute_reply": "2021-09-27T07:18:27.395939Z",
     "shell.execute_reply.started": "2021-09-27T07:18:27.375650Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 15:18:27.380 | INFO     | jpy_tools.parseSnake2:addRule:55 - basecall step num: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "## get parameter of rule `basecall` ##\n",
       "df_basecall = df_splitH5.copy()\n",
       "df_basecall[\"nparts\"] = df_basecall[\"nparts\"].map(lambda x: list(range(x)))\n",
       "df_basecall = df_basecall.explode(\"nparts\")\n",
       "df_basecall = df_basecall[[\"nparts\", \"dir_output\"]]\n",
       "df_basecall['sample'] = df_basecall.index\n",
       "df_basecall.index = df_basecall.index + df_basecall.nparts.astype(str)\n",
       "df_basecall.dir_output = df_basecall.dir_output + df_basecall.nparts.astype(str) + '/'\n",
       "df_basecall['basecalledDir'] = df_basecall.index + '/'\n",
       "df_basecall['guppy'] = config['guppy']\n",
       "df_basecall['model'] = config['model']\n",
       "for column in ['basecalledDir']:\n",
       "    df_basecall[column] = resultDir + 'step2_basecall/' + df_basecall[column]\n",
       "\n",
       "def parseDfToInput_basecall_splitH5(wildcard):\n",
       "    selfWildCardUnique = True\n",
       "    if isinstance(df_basecall.at[wildcard.sampleSplit, 'sample'], list):\n",
       "        selfWildCardUnique = False\n",
       "    if selfWildCardUnique:\n",
       "        return resultDir + 'step1_splitH5/' + df_basecall.at[wildcard.sampleSplit, 'sample'] + '.finished'\n",
       "    else:\n",
       "        return [resultDir + 'step1_splitH5/' + x + '.finished' for x in df_basecall.loc[wildcard.sampleSplit, 'sample']]\n",
       "\n",
       "def parseDfToParams_basecall_splitH5_need_h5(wildcard):\n",
       "    selfWildCardUnique = True\n",
       "    if isinstance(df_basecall.at[wildcard.sampleSplit, 'sample'], list):\n",
       "        selfWildCardUnique = False\n",
       "    if selfWildCardUnique:\n",
       "        fromSampleName = df_basecall.at[wildcard.sampleSplit, 'sample']\n",
       "        return df_splitH5.at[fromSampleName, 'need_h5']\n",
       "    else:\n",
       "        ls_fromSampleName = df_basecall.loc[wildcard.sampleSplit, 'sample']\n",
       "        return [df_splitH5.at[x, 'need_h5'] for x in ls_fromSampleName]\n",
       "----------------\n",
       "IN RULE\n",
       "----------------\n",
       "# parameter's dataframe of basecall: \n",
       "# |       |   nparts | dir_output   | sample   | basecalledDir   | guppy                                          | model                                                    |\n",
       "# |:------|---------:|:-------------|:---------|:----------------|:-----------------------------------------------|:---------------------------------------------------------|\n",
       "# | all0  |        0 | all/0/       | all      | all0/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all1  |        1 | all/1/       | all      | all1/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all2  |        2 | all/2/       | all      | all2/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all3  |        3 | all/3/       | all      | all3/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all4  |        4 | all/4/       | all      | all4/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all5  |        5 | all/5/       | all      | all5/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all6  |        6 | all/6/       | all      | all6/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all7  |        7 | all/7/       | all      | all7/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all8  |        8 | all/8/       | all      | all8/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all9  |        9 | all/9/       | all      | all9/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all10 |       10 | all/10/      | all      | all10/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "# | all11 |       11 | all/11/      | all      | all11/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
       "rule basecall:\n",
       "    input:\n",
       "        splitH5Finished = parseDfToInput_basecall_splitH5,\n",
       "    output:\n",
       "        basecallFinished = resultDir + 'step2_basecall/' + '{sampleSplit}.finished',\n",
       "    params:\n",
       "        gpu = 2,\n",
       "        need_h5 = parseDfToParams_basecall_splitH5_need_h5,\n",
       "        dir_output = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'dir_output'],\n",
       "        basecalledDir = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'basecalledDir'],\n",
       "        guppy = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'guppy'],\n",
       "        model = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'model'],\n",
       "    threads:18\n",
       "    priority:0\n",
       "    shell:\n",
       "        \"\"\"\n",
       "if [ {params.need_h5} = True ]\n",
       "then\n",
       "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings --fast5_out\n",
       "else\n",
       "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings\n",
       "fi\n",
       "touch {output.basecallFinished}\n",
       "        \"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_basecall = jps.SnakeRule(sf, \"basecall\", 18, 2, wildCard=\"sampleSplit\")\n",
    "rule_basecall.addCode(\n",
    "    \"\"\"\n",
    "df_basecall = df_splitH5.copy()\n",
    "df_basecall[\"nparts\"] = df_basecall[\"nparts\"].map(lambda x: list(range(x)))\n",
    "df_basecall = df_basecall.explode(\"nparts\")\n",
    "df_basecall = df_basecall[[\"nparts\", \"dir_output\"]]\n",
    "df_basecall['sample'] = df_basecall.index\n",
    "df_basecall.index = df_basecall.index + df_basecall.nparts.astype(str)\n",
    "df_basecall.dir_output = df_basecall.dir_output + df_basecall.nparts.astype(str) + '/'\n",
    "df_basecall['basecalledDir'] = df_basecall.index + '/'\n",
    "df_basecall['guppy'] = config['guppy']\n",
    "df_basecall['model'] = config['model']\n",
    "\"\"\"\n",
    ")\n",
    "rule_basecall.addMetaDf(\"df_basecall\", [\"basecalledDir\"], metaDf = df_basecall)\n",
    "rule_basecall.addMain(\"params\", [\"need_h5\"], rule_splitH5)\n",
    "rule_basecall.addMain(\"params\", [\"dir_output\", \"basecalledDir\", \"guppy\", \"model\"])\n",
    "\n",
    "rule_basecall.setShell(\"\"\"\n",
    "if [ {params.need_h5} = True ]\n",
    "then\n",
    "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings --fast5_out\n",
    "else\n",
    "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings\n",
    "fi\n",
    "\"\"\")\n",
    "rule_basecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:18:33.694486Z",
     "iopub.status.busy": "2021-09-27T07:18:33.694001Z",
     "iopub.status.idle": "2021-09-27T07:18:33.709583Z",
     "shell.execute_reply": "2021-09-27T07:18:33.708190Z",
     "shell.execute_reply.started": "2021-09-27T07:18:33.694442Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mergeFq = df_basecall.reset_index().groupby(\"sample\")[\"index\"].agg(list).pipe(\n",
    "    pd.DataFrame\n",
    ").rename(columns={\"index\": \"sampleSplit\"}).assign(dir_out=lambda df: df.index + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:18:54.737628Z",
     "iopub.status.busy": "2021-09-27T07:18:54.737248Z",
     "iopub.status.idle": "2021-09-27T07:18:54.748039Z",
     "shell.execute_reply": "2021-09-27T07:18:54.747379Z",
     "shell.execute_reply.started": "2021-09-27T07:18:54.737595Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 15:18:54.740 | INFO     | jpy_tools.parseSnake2:addRule:55 - mergeFq step num: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "## get parameter of rule `mergeFq` ##\n",
       "df_mergeFq = df_basecall.reset_index().groupby(\"sample\")[\"index\"].agg(list).pipe(\n",
       "    pd.DataFrame\n",
       ").rename(columns={\"index\": \"sampleSplit\"}).assign(dir_out=lambda df: df.index + \"/\")\n",
       "for column in ['dir_out']:\n",
       "    df_mergeFq[column] = resultDir + 'step3_mergeFq/' + df_mergeFq[column]\n",
       "\n",
       "def parseDfToInput_mergeFq_basecall(wildcard):\n",
       "    selfWildCardUnique = True\n",
       "    if isinstance(df_mergeFq.at[wildcard.sample, 'sampleSplit'], list):\n",
       "        selfWildCardUnique = False\n",
       "    if selfWildCardUnique:\n",
       "        return resultDir + 'step2_basecall/' + df_mergeFq.at[wildcard.sample, 'sampleSplit'] + '.finished'\n",
       "    else:\n",
       "        return [resultDir + 'step2_basecall/' + x + '.finished' for x in df_mergeFq.loc[wildcard.sample, 'sampleSplit']]\n",
       "\n",
       "def parseDfToParams_mergeFq_basecall_basecalledDir(wildcard):\n",
       "    selfWildCardUnique = True\n",
       "    if isinstance(df_mergeFq.at[wildcard.sample, 'sampleSplit'], list):\n",
       "        selfWildCardUnique = False\n",
       "    if selfWildCardUnique:\n",
       "        fromSampleName = df_mergeFq.at[wildcard.sample, 'sampleSplit']\n",
       "        return df_basecall.at[fromSampleName, 'basecalledDir']\n",
       "    else:\n",
       "        ls_fromSampleName = df_mergeFq.loc[wildcard.sample, 'sampleSplit']\n",
       "        return [df_basecall.at[x, 'basecalledDir'] for x in ls_fromSampleName]\n",
       "----------------\n",
       "IN RULE\n",
       "----------------\n",
       "# parameter's dataframe of mergeFq: \n",
       "# | sample   | sampleSplit                                                                                        | dir_out   |\n",
       "# |:---------|:---------------------------------------------------------------------------------------------------|:----------|\n",
       "# | all      | ['all0', 'all1', 'all2', 'all3', 'all4', 'all5', 'all6', 'all7', 'all8', 'all9', 'all10', 'all11'] | all/      |\n",
       "rule mergeFq:\n",
       "    input:\n",
       "        basecallFinished = parseDfToInput_mergeFq_basecall,\n",
       "    output:\n",
       "        mergeFqFinished = resultDir + 'step3_mergeFq/' + '{sample}.finished',\n",
       "    params:\n",
       "        gpu = 0,\n",
       "        basecalledDir = parseDfToParams_mergeFq_basecall_basecalledDir,\n",
       "        dir_out = lambda wildcard: df_mergeFq.at[wildcard.sample, 'dir_out'],\n",
       "    threads:18\n",
       "    priority:0\n",
       "    shell:\n",
       "        \"\"\"\n",
       "mkdir -p {params.dir_out}\n",
       "cd {pipelineDir}\n",
       "python mergeFastq.py {params.basecalledDir} -o {params.dir_out} -t {threads}\n",
       "touch {output.mergeFqFinished}\n",
       "        \"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_mergeFq = jps.SnakeRule(sf, 'mergeFq', 18, 0)\n",
    "rule_mergeFq.addCode(\"\"\"\n",
    "df_mergeFq = df_basecall.reset_index().groupby(\"sample\")[\"index\"].agg(list).pipe(\n",
    "    pd.DataFrame\n",
    ").rename(columns={\"index\": \"sampleSplit\"}).assign(dir_out=lambda df: df.index + \"/\")\n",
    "\"\"\")\n",
    "rule_mergeFq.addMetaDf('df_mergeFq', ['dir_out'], metaDf=df_mergeFq)\n",
    "rule_mergeFq.addMain('params', ['basecalledDir'], fromRule=rule_basecall)\n",
    "rule_mergeFq.addMain('params', ['dir_out'])\n",
    "rule_mergeFq.setShell(\"\"\"\n",
    "mkdir -p {params.dir_out}\n",
    "cd {pipelineDir}\n",
    "python mergeFastq.py {params.basecalledDir} -o {params.dir_out} -t {threads}\n",
    "\"\"\")\n",
    "rule_mergeFq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:19:05.571853Z",
     "iopub.status.busy": "2021-09-27T07:19:05.571477Z",
     "iopub.status.idle": "2021-09-27T07:19:05.577631Z",
     "shell.execute_reply": "2021-09-27T07:19:05.576756Z",
     "shell.execute_reply.started": "2021-09-27T07:19:05.571820Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rule all:\n",
       "    input:\n",
       "        mergeFqFinished = [resultDir + 'step3_mergeFq/' + \"\" + sample + \".finished\" for sample in df_mergeFq.index],"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_all = jps.SnakeAll(sf, rule_mergeFq)\n",
    "rule_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T07:19:06.398429Z",
     "iopub.status.busy": "2021-09-27T07:19:06.398113Z",
     "iopub.status.idle": "2021-09-27T07:19:06.403358Z",
     "shell.execute_reply": "2021-09-27T07:19:06.402498Z",
     "shell.execute_reply.started": "2021-09-27T07:19:06.398400Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "#configfile: \"/public/home/liuzj/scripts/pipeline/basecallByGuppy/snakemake/config.yaml\"\n",
      "pipelineDir = config['pipelineDir']\n",
      "resultDir = config[\"resultDir\"].rstrip(\"/\") + \"/\"\n",
      "pipelineDir = config[\"pipelineDir\"].rstrip(\"/\") + \"/\"\n",
      "\n",
      "\n",
      "## get parameter of rule `splitH5` ##\n",
      "import pandas as pd\n",
      "dt_h5 = config['input']\n",
      "df_splitH5 = pd.DataFrame.from_dict(dt_h5).T\n",
      "df_splitH5['dir_output'] = df_splitH5.index + '/'\n",
      "for column in ['dir_output']:\n",
      "    df_splitH5[column] = resultDir + 'step1_splitH5/' + df_splitH5[column]\n",
      "\n",
      "\n",
      "## get parameter of rule `basecall` ##\n",
      "df_basecall = df_splitH5.copy()\n",
      "df_basecall[\"nparts\"] = df_basecall[\"nparts\"].map(lambda x: list(range(x)))\n",
      "df_basecall = df_basecall.explode(\"nparts\")\n",
      "df_basecall = df_basecall[[\"nparts\", \"dir_output\"]]\n",
      "df_basecall['sample'] = df_basecall.index\n",
      "df_basecall.index = df_basecall.index + df_basecall.nparts.astype(str)\n",
      "df_basecall.dir_output = df_basecall.dir_output + df_basecall.nparts.astype(str) + '/'\n",
      "df_basecall['basecalledDir'] = df_basecall.index + '/'\n",
      "df_basecall['guppy'] = config['guppy']\n",
      "df_basecall['model'] = config['model']\n",
      "for column in ['basecalledDir']:\n",
      "    df_basecall[column] = resultDir + 'step2_basecall/' + df_basecall[column]\n",
      "\n",
      "def parseDfToInput_basecall_splitH5(wildcard):\n",
      "    selfWildCardUnique = True\n",
      "    if isinstance(df_basecall.at[wildcard.sampleSplit, 'sample'], list):\n",
      "        selfWildCardUnique = False\n",
      "    if selfWildCardUnique:\n",
      "        return resultDir + 'step1_splitH5/' + df_basecall.at[wildcard.sampleSplit, 'sample'] + '.finished'\n",
      "    else:\n",
      "        return [resultDir + 'step1_splitH5/' + x + '.finished' for x in df_basecall.loc[wildcard.sampleSplit, 'sample']]\n",
      "\n",
      "def parseDfToParams_basecall_splitH5_need_h5(wildcard):\n",
      "    selfWildCardUnique = True\n",
      "    if isinstance(df_basecall.at[wildcard.sampleSplit, 'sample'], list):\n",
      "        selfWildCardUnique = False\n",
      "    if selfWildCardUnique:\n",
      "        fromSampleName = df_basecall.at[wildcard.sampleSplit, 'sample']\n",
      "        return df_splitH5.at[fromSampleName, 'need_h5']\n",
      "    else:\n",
      "        ls_fromSampleName = df_basecall.loc[wildcard.sampleSplit, 'sample']\n",
      "        return [df_splitH5.at[x, 'need_h5'] for x in ls_fromSampleName]\n",
      "\n",
      "\n",
      "## get parameter of rule `mergeFq` ##\n",
      "df_mergeFq = df_basecall.reset_index().groupby(\"sample\")[\"index\"].agg(list).pipe(\n",
      "    pd.DataFrame\n",
      ").rename(columns={\"index\": \"sampleSplit\"}).assign(dir_out=lambda df: df.index + \"/\")\n",
      "for column in ['dir_out']:\n",
      "    df_mergeFq[column] = resultDir + 'step3_mergeFq/' + df_mergeFq[column]\n",
      "\n",
      "def parseDfToInput_mergeFq_basecall(wildcard):\n",
      "    selfWildCardUnique = True\n",
      "    if isinstance(df_mergeFq.at[wildcard.sample, 'sampleSplit'], list):\n",
      "        selfWildCardUnique = False\n",
      "    if selfWildCardUnique:\n",
      "        return resultDir + 'step2_basecall/' + df_mergeFq.at[wildcard.sample, 'sampleSplit'] + '.finished'\n",
      "    else:\n",
      "        return [resultDir + 'step2_basecall/' + x + '.finished' for x in df_mergeFq.loc[wildcard.sample, 'sampleSplit']]\n",
      "\n",
      "def parseDfToParams_mergeFq_basecall_basecalledDir(wildcard):\n",
      "    selfWildCardUnique = True\n",
      "    if isinstance(df_mergeFq.at[wildcard.sample, 'sampleSplit'], list):\n",
      "        selfWildCardUnique = False\n",
      "    if selfWildCardUnique:\n",
      "        fromSampleName = df_mergeFq.at[wildcard.sample, 'sampleSplit']\n",
      "        return df_basecall.at[fromSampleName, 'basecalledDir']\n",
      "    else:\n",
      "        ls_fromSampleName = df_mergeFq.loc[wildcard.sample, 'sampleSplit']\n",
      "        return [df_basecall.at[x, 'basecalledDir'] for x in ls_fromSampleName]\n",
      "\n",
      "rule all:\n",
      "    input:\n",
      "        mergeFqFinished = [resultDir + 'step3_mergeFq/' + \"\" + sample + \".finished\" for sample in df_mergeFq.index],\n",
      "\n",
      "# parameter's dataframe of splitH5: \n",
      "# |     | need_h5   |   nparts | path                                                                                    | dir_output   |\n",
      "# |:----|:----------|---------:|:----------------------------------------------------------------------------------------|:-------------|\n",
      "# | all | False     |       12 | /scem/work/liuzj/projects/mouse/allFast5/20210723_1345_MN29338_FAQ41752_7386409e/fast5/ | all/         |\n",
      "rule splitH5:\n",
      "    input:\n",
      "        path = lambda wildcard: df_splitH5.at[wildcard.sample, 'path'],\n",
      "    output:\n",
      "        splitH5Finished = resultDir + 'step1_splitH5/' + '{sample}.finished',\n",
      "    params:\n",
      "        gpu = 0,\n",
      "        nparts = lambda wildcard: df_splitH5.at[wildcard.sample, 'nparts'],\n",
      "        dir_output = lambda wildcard: df_splitH5.at[wildcard.sample, 'dir_output'],\n",
      "    threads:1\n",
      "    priority:0\n",
      "    shell:\n",
      "        \"\"\"\n",
      "cd {pipelineDir}\n",
      "python ./splitFast5ToMultipleDir.py -i {input.path} -o {params.dir_output} -n {params.nparts}\n",
      "touch {output.splitH5Finished}\n",
      "        \"\"\"\n",
      "\n",
      "# parameter's dataframe of basecall: \n",
      "# |       |   nparts | dir_output   | sample   | basecalledDir   | guppy                                          | model                                                    |\n",
      "# |:------|---------:|:-------------|:---------|:----------------|:-----------------------------------------------|:---------------------------------------------------------|\n",
      "# | all0  |        0 | all/0/       | all      | all0/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all1  |        1 | all/1/       | all      | all1/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all2  |        2 | all/2/       | all      | all2/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all3  |        3 | all/3/       | all      | all3/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all4  |        4 | all/4/       | all      | all4/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all5  |        5 | all/5/       | all      | all5/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all6  |        6 | all/6/       | all      | all6/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all7  |        7 | all/7/       | all      | all7/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all8  |        8 | all/8/       | all      | all8/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all9  |        9 | all/9/       | all      | all9/           | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all10 |       10 | all/10/      | all      | all10/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "# | all11 |       11 | all/11/      | all      | all11/          | ~/softwares/ont-guppy-4.2/bin/guppy_basecaller | ~/softwares/ont-guppy-4.2/data/dna_r9.4.1_450bps_hac.cfg |\n",
      "rule basecall:\n",
      "    input:\n",
      "        splitH5Finished = parseDfToInput_basecall_splitH5,\n",
      "    output:\n",
      "        basecallFinished = resultDir + 'step2_basecall/' + '{sampleSplit}.finished',\n",
      "    params:\n",
      "        gpu = 2,\n",
      "        need_h5 = parseDfToParams_basecall_splitH5_need_h5,\n",
      "        dir_output = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'dir_output'],\n",
      "        basecalledDir = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'basecalledDir'],\n",
      "        guppy = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'guppy'],\n",
      "        model = lambda wildcard: df_basecall.at[wildcard.sampleSplit, 'model'],\n",
      "    threads:18\n",
      "    priority:0\n",
      "    shell:\n",
      "        \"\"\"\n",
      "if [ {params.need_h5} = True ]\n",
      "then\n",
      "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings --fast5_out\n",
      "else\n",
      "    {params.guppy} -c {params.model} -i {params.dir_output} --qscore_filtering --min_qscore=7 -s {params.basecalledDir} -x \"cuda:all:100%\" --disable_pings\n",
      "fi\n",
      "touch {output.basecallFinished}\n",
      "        \"\"\"\n",
      "\n",
      "# parameter's dataframe of mergeFq: \n",
      "# | sample   | sampleSplit                                                                                        | dir_out   |\n",
      "# |:---------|:---------------------------------------------------------------------------------------------------|:----------|\n",
      "# | all      | ['all0', 'all1', 'all2', 'all3', 'all4', 'all5', 'all6', 'all7', 'all8', 'all9', 'all10', 'all11'] | all/      |\n",
      "rule mergeFq:\n",
      "    input:\n",
      "        basecallFinished = parseDfToInput_mergeFq_basecall,\n",
      "    output:\n",
      "        mergeFqFinished = resultDir + 'step3_mergeFq/' + '{sample}.finished',\n",
      "    params:\n",
      "        gpu = 0,\n",
      "        basecalledDir = parseDfToParams_mergeFq_basecall_basecalledDir,\n",
      "        dir_out = lambda wildcard: df_mergeFq.at[wildcard.sample, 'dir_out'],\n",
      "    threads:18\n",
      "    priority:0\n",
      "    shell:\n",
      "        \"\"\"\n",
      "mkdir -p {params.dir_out}\n",
      "cd {pipelineDir}\n",
      "python mergeFastq.py {params.basecalledDir} -o {params.dir_out} -t {threads}\n",
      "touch {output.mergeFqFinished}\n",
      "        \"\"\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sf.getMain(path_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4906a907f3ce955ec173348abbed4e32ce81f1d00a5c31187a4d8f78431ced8f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
